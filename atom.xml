<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Yabage]]></title>
  <link href="http://pierre-jean.baraud.fr/atom.xml" rel="self"/>
  <link href="http://pierre-jean.baraud.fr/"/>
  <updated>2016-07-23T10:44:25+01:00</updated>
  <id>http://pierre-jean.baraud.fr/</id>
  <author>
    <name><![CDATA[Pierre-Jean Baraud]]></name>
    <email><![CDATA[pierre-jean@baraud.fr]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Review of Two Software Craftsmanship Books]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2016/07/18/two-software-craftsmanship-books-review/"/>
    <updated>2016-07-18T23:16:54+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2016/07/18/two-software-craftsmanship-books-review</id>
    <content type="html"><![CDATA[<p><img class="center" src="http://pierre-jean.baraud.fr/images/books/cover-battle.png"></p>

<p>Today I am gonna give you a quick review of the last two books I read: <a href="http://www.informit.com/store/clean-coder-a-code-of-conduct-for-professional-programmers-9780137081073">The Clean Coder</a>, by <em>Robert C. Martin</em> (aka <em>Uncle Bob</em>), and <a href="http://www.informit.com/store/software-craftsman-professionalism-pragmatism-pride-9780134052502">The Software Craftsman</a>, by <em>Sandro Mancuso</em>.
Both books cover the same topic: the <strong>Software Craftsmanship</strong> movement.</p>

<!-- More -->


<h2>The Software What ?</h2>

<p>Remember my <a href="http://pierre-jean.baraud.fr/blog/2013/08/10/be-passionate/">first blog post about passion</a> ? Well, if I had to rewrite it today I would title it &ldquo;Be passionate, be a Software Craftsman&rdquo;.</p>

<p>Yes, Software Craftsmanship is all about passion. But it is also much more than that, and taught me a lot about my own weaknesses.</p>

<h3>Professionalism</h3>

<p>Software Craftsmanship is about <em>professionalism</em>: the subtitle of the first book is <em>&ldquo;A Code of Conduct for <strong>Professional</strong> Programmers&rdquo;</em>, and of the second one is <em>&ldquo;<strong>Professionalism</strong>, Pragmatism, Pride&rdquo;</em>. If the message was not clear enough, you will find a reference to professionalism in every paragraph, if not sentence.</p>

<p>And this is where my previous vision fell short, and the first big lesson I learnt. Before reading these books, I figured the business world and true passion as natural opposites. I suggested to embrace your hobby and to not care about this corporate guys in suits that would crash your dream trying to make you do &ldquo;just a job&rdquo;. In a word: I was childish.
I was thinking that success will come if you were motivated enough, and that only startup companies promoting cool-t-shirt-dress-code had understood the future of our industry. I was blaming everyone except me for things that may not go well in failing projects, companies or culture environment. I was acting as the opposite of a Software Craftsman, as this movement is all about taking responsibility, involvement in the project and in the company you are working for, and spreading the culture of passion with new technical disciplines.</p>

<h3>Disciplines and Values</h3>

<p>Speaking about disciplines: you may expect this book to teach you a set of disciplines to apply in order to succeed in any situation. And even if it does mention a set of practices (like <em>Test Driven Development</em>, <em>Pair programming</em> or <em>SOLID principles</em>), these books are <strong>not</strong> about these disciplines. These books are about <strong>values</strong>. It&rsquo;s a long term vision about our industry, the mistakes made, and how some current disciplines and attitudes can solve these common issues. It is not about the implementation of these disciplines. It is also not about having a fanboy attitude for such technology or methodology, but only for the value they bring. It&rsquo;s a pragmatic approach that should prevent irrational adoration of techniques and sterile debate with troll. When I told you these Software Craftsmen are spoiling all the fun&hellip;</p>

<h3>Tell me more</h3>

<p>I won&rsquo;t summarize here the content of the books. Many resources about Software Craftsmanship are already available online. If you are interested, you can watch one of the public presentations the authors gave (for instance <a href="https://www.youtube.com/watch?v=9OhXqBlCmrM">here</a> and <a href="https://www.youtube.com/watch?v=9Xy3QC7yxJw">there</a>) covering in some ways the same topic as the books. The value of these books is not so much about the topic they cover but how they illustrate each idea through different examples that speak to each one of us.</p>

<h2>A common subject, two great authors</h2>

<p>So if both books speak about the same topic, are they should you read both? Are they tackling the topic the same way? What are their differences?</p>

<h3>Obviously close</h3>

<p>As they are both covering a common topic, you will inevitably find similarities between the two books (&ldquo;TDD&rdquo;, &ldquo;Commitment&rdquo;, &ldquo;How to say No&rdquo;). Moreover, the narrative of both books follows the same structure: each concept is illustrated with a personal experience from the author, creating a bridge between the theory and the practice.</p>

<p>Both authors don&rsquo;t hesitate to express their personal opinions and are also amazing public speaker. You can feel that in the book and you will never feel bored.</p>

<h3>But not the same</h3>

<p>The first noticeable difference can already be seen in the title: The Clean Coder does not mention the Software Craftsmanship movement. His book actually focuses entirely on the notion of professionalism. Don&rsquo;t throw stones at me yet for comparing the incomparable: once reached the last two pages of the book, the author finally defines what is a Software Craftsman and connects it with the rest of the book. Sandro&rsquo;s book is much more direct and addresses the topic since the first chapter.</p>

<p>The second difference is the generation of the authors. Robert C. Martin has entered the computer industry from the bottom of the ladder (and raised himself to the very top of it), in times where software was tightly coupled with hardware. He has seen the evolution of our industry during his quite extensive career. This experience reflects to his speech and provides him an interesting perspective on things. His advices are more timeless. In a way, his book is loosely coupled with the temporal context of the reader.</p>

<p>On the other hand, Sandro Mancuso has a more &ldquo;classic&rdquo; career: he graduated as a software developer and entered the industry as an already talented and high skilled professional. He&rsquo;s also younger and maybe his experience will resonate more with the average developer. But not many of us can pretend to have the same impressive career. Sandro obstinately challenged himself to raise his level and reach his main goal. Changing country or quitting job just to pass an interview are some of the many things he went through. He is, like Robert C. Martin, a well-known and respected figure of the Software Craftsmanship community. Despite his versatile professional experience, you will find his book more settled in the current period context. His book focuses on the failures of Agile movement (a movement born in 2001 and still growing today as some companies are just starting to adopt it).</p>

<p>Finally, both books have been written at different times: 2011 for <em>The Clean Coder</em> and 2014 for <em>The Software Craftsman</em>. This allows the second one to make different references to the first one. It will then seems normal that you may find complementary information between both books.</p>

<h2>Food for the mind</h2>

<p>Whatever which one of the two books you read, they will certainly achieve the same result: open new perspectives, provide a big shot of motivation and reconcile yourself with many situations you would have defined as problematic before.</p>

<p>During your reading, you will learn on how to raise yourself to the level of software craftsman without sacrificing your ethic and your personal life.
But this books may also leave you with a strange feeling, they may open doors without you noticing. By questioning your work life, you will also challenge your definition of happiness, your goals in life and maybe even rediscover your own identity &hellip; It is of course not the purpose of Software Craftsmanship books to answer such philosophical questions, but be prepared to face them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TTY: Under the Hood]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2016/07/08/journey-to-the-tty/"/>
    <updated>2016-07-08T12:00:00+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2016/07/08/journey-to-the-tty</id>
    <content type="html"><![CDATA[<p>It all started with the simple instruction: <code>-t</code> <em>flag assigns a pseudo-tty or terminal inside the new container</em>&hellip; and a moment of puzzlement&hellip; <em>What is exactly a pseudo TTY?</em> <em>What does it mean to attach or detach a process from it?</em></p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/gnome-terminal.png"></p>

<p>Beware my friend, for this article will lead you into the depths of forgotten history, guiding you through arcane kernel mechanisms. But persevere and the pure light of knowledge will shine upon you by the end of this journey.</p>

<!-- More -->


<h2>The origin of the myth: the Teletype</h2>

<p>When you go all Neo from Matrix by popping up a fancy green terminal to impress your friends around (what do you mean, <em>&ldquo;nobody does that&rdquo;</em>?), you are actually playing with the legacy of a very old device that few have ever seen in their lives: the Teletype.</p>

<h3>A legendary object</h3>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/teletype-model-28.jpg"></p>

<p>Do you see this beauty in the picture? That&rsquo;s a Teletype. A <em>model 28</em> by <em>Teletype Corporation</em> to be precise. However there are countless models built by many different forgotten companies. The history of teletypes finds its roots in initial experimentation during the late 1800s, but truly began in the 1920s approaching an end in the 70s when fax technology began to be good enough to replace them.</p>

<p>A teletype is basically a machine that sends letters you typed on the keyboard through electric signals to another machine or network, and prints (literally prints, on paper!) letters received through the reception cable. Obviously, the different models evolved with time to offer more features and performance possibilites:</p>

<ul>
<li>Use of <em>Multiplex signal</em>, in order to allow the usage of one physical cable to send and receive messages</li>
<li>Support of <em>punched card</em> to send prepared messages at full speed without the need of typing them</li>
<li>Use of video screen (you&rsquo;re welcome, trees!)</li>
<li>Increase of speed (from 50 baud to 150000 baud)</li>
</ul>


<p>At the time this type of machine was the best way to transmit data in fast and reliable way.</p>

<h3>Stop your boring old gibberish&hellip; Why the heck are you telling me about this?</h3>

<p>Because instead of building new devices to interact with computers, pragmatic people at the time decided to reuse existing teletypes to connect to them.
Listen very carefully, I&rsquo;m not talking here about the <em>Personal Computer</em> (PC) you are familiar with. I&rsquo;m talking about a big, massive machine located in its own dedicated room to which you had no access if you were not cool enough, and where you had to send commands from the teletype and read the output printed back on the device.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/mainframe2.jpg"></p>

<p>Actually, one terminal was directly connected to the machine within the same room : <em>the console</em>. Man, I can&rsquo;t tell you about the kudos and props at being the lucky one behind the console. Well, I can&rsquo;t because I&rsquo;m not that old, but I&rsquo;m sure that it should have been a big deal back then.</p>

<p>Anyway, by now we&rsquo;ve realized a few things: for instance when using a terminal it&rsquo;s nice to see what you are typing. So what about asking the computer to echo back to us what it received, so that it is printed from our teletype? And what about erasing with backspace what has been typed? Yep, the computer at the end of the cable should take care of that for us, we&rsquo;re only using a dummy Teletype after all.</p>

<h3>Under the hood</h3>

<p>Here is a diagram of how a teletype interacted with a computer:</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/teletype-mainframe-workflow.png"></p>

<ol>
<li>Each machine is -conceptually or physically- connected via two cables: one to send instructions to the computer and one to receive output from the computer.</li>
<li>These cables are connected to the computer through a serial cable plugged into an Universal Asynchronous Receiver and Transmitter (<em>UART</em>) that transforms the asynchronous flow of data into bytes words.</li>
<li>The computer has an UART driver to read for the hardware device.</li>
<li>The sequence of characters is passed to the line discipline. The line discipline will be in charge of converting special characters (like <em>end of line</em>, <em>backspaces</em>), and echoing (reprinting) what has been received back to the teletype, so that the user can visualize what he/she types.</li>
<li>The flow of instruction is passed to the TTY driver, that then passes them to the <em>foreground</em> processes for the <em>session</em> associated with this TTY. Indeed, as a user, you can execute several processes in parallel, but only interact with one at a time, letting the others working (or waiting) in the background.</li>
</ol>


<p>The whole stack as defined above is called a <em>TTY device</em>, and several ones can exist at the same time for a computer. So different line disciplines can be set for different devices, each TTY having its own foreground job, etc.</p>

<h2>From the Teletype to the Terminal</h2>

<p>Besides unpredictable haircuts and memorable rythms, the 80s have also brought us what they called <em>intelligent terminals</em>. Slowly, terminals evolved to become badass devices, with screen, memory, and even small processors to manage specific features on their side.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/terminal_vt100.jpg"></p>

<p>They started to <em>look like</em> your current PC desktop. But Beware they are in no way comparable! They are still dummy objects, despite their name. They do not compute things on their own: managing fancy colors and having a fast refresh frequency is far from being even close to a computer. It&rsquo;s the 80s after all, it&rsquo;s hard to call anything from that period of time smart&hellip;</p>

<p>These devices worked in the same way as teletypes, but also introduced some new features that needed supported from the software to be managed correctly (colors, special movements, etc).</p>

<h2>Wake up Neo, it is all virtual</h2>

<p>The massive set of wardrobes that used to constitute a computer gradually shrunk in size to a nice little box that you could fit under your desk. And there were no more endless terminals connected to it, only one monitor and one keyboard. Nevertheless, your current Linux machine keeps emulating several (usually 7 by default) terminals connected to your hardware. But to protect you from the effort of getting up and physically going to another chair, the OS allows you to switch from one terminal to another by a simple press of keys (<code>Ctrl</code>+<code>Alt</code>+<code>F1</code> to <code>Ctrl</code>+<code>Alt</code>+<code>F7</code>). This feature is called <em>virtual terminals</em>, and is represented by the files <code>/dev/tty1</code> to <code>/dev/tty7</code>. You can see any of these files as a duplex cable connected to a terminal. If you write to it, you send the information to be printed to the terminal. If you read from it, you receive what is typed from the terminal (try it, it works).</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/virtual-terminal-workflow.png"></p>

<p>When you switch from one virtual terminal to another, the OS detaches your <em>seat</em> (a set of input and output devices like monitor, keyboard, mouse, etc. representing the hardware interface with the user) from the first virtual terminal and attaches it to the one requested by your shortcut. The processes from the first virtual terminals keep running, writing and reading from their virtual tty file (<code>dev/tty1</code> for instance), but this file won&rsquo;t receive any event from the seat and won&rsquo;t be able to send output to the seat. The information will be buffered instead (until you reattach your seat to this terminal), making the switch between sessions transparent for running jobs.</p>

<h2>I know no master</h2>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/matrix-operator.jpg"></p>

<p>Yet I imagine only a few of you are actually using the virtual tty just mentioned. You are usually using a terminal console application launched from a graphic environment that is itself launched from a virtual terminal (yep, take a deep breath and read that again).</p>

<p>So when you launch your favorite terminal emulator like <em>xterm</em> or <em>gnome-terminal</em>, how do the processes know where to write the output, and where to get the input from?</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/ptmx-pts-workflow.png"></p>

<p>Basically, when you launch a terminal within a graphic environment like this, it will spawn its own equivalent of <code>/dev/ttyX</code>: the terminal emulator will open a special file located in <code>/dev/ptmx</code>, called the <em>master side</em> of the <em>pts</em>, will work some magic with <code>ioctl</code> function, which will create a <em>slave side</em> of the pts in <code>/dev/pts/X</code>.</p>

<p>The processes running in the session will be attached to this file, that will behave like any file from the virtual terminal, except that there is no attachment to a seat: you can open several terminal emulator windows at the same time and display them side by side, having different sessions running in parallel.</p>

<h2>Going further</h2>

<p>We could dig into the topic endlessly, discussing the function <code>ioctl</code>, detailing how the kernel handles the session, expressing our endless admiration for the great 70s look of the <a href="http://terminals.classiccmp.org/wiki/images/f/fb/DEC_VT05_121708587772-2.jpg">DEC VT05</a> terminal&hellip;
But we should keep some for further articles, and there are anyway plenty of great resources already available if you are interested. To share a few:</p>

<ul>
<li><a href="http://www.linusakesson.net/programming/tty/">the TTY demystified, by Linus Åkesson</a>: Simply <em>the</em> reference on the topic, that will also explain signals, processes, etc.</li>
<li><a href="https://dvdhrm.wordpress.com/2013/08/24/session-management-on-linux/">Ponyhof&rsquo;s session management</a> and <a href="https://dvdhrm.wordpress.com/2013/08/24/how-vt-switching-works/">vt-switching</a> articles: Great to understand the session and seats concepts.</li>
<li><a href="http://unix.stackexchange.com/questions/117981/what-are-the-responsibilities-of-each-pseudo-terminal-pty-component-software">Unix StackExchange</a> Stéphane Chazelas&#8217; answer, that makes a lot of effort to clarify what was initially confusing for me.</li>
</ul>


<p>I realize I took a lot of shortcuts in this article and it would be natural that some part suggest greater depths to be explored. So if you have any question or need further details, please leave a comment, I will try my best to provide a clear answer!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux Boot Process in a Nutshell]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/06/04/linux-boot-process/"/>
    <updated>2014-06-04T19:41:30+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/06/04/linux-boot-process</id>
    <content type="html"><![CDATA[<p><img class="center" src="http://pierre-jean.baraud.fr/images/linux/power-on-1.jpg"></p>

<p>I&rsquo;m getting more and more interested in how my system works &ldquo;under the hood&rdquo; lately. These fundations are essential to understand some behaviors / technical choices in technologies oriented for end users (such as <a href="http://docker.io">Docker</a>).</p>

<p>That&rsquo;s why I decided to write, mostly as a reminder for myself, a serie of articles explaining some fundamental Linux mechanisms. As I have to start somewhere, I&rsquo;ll start with the boot process.</p>

<!-- More -->


<p><strong>Disclaimer: I will assume the machine is running with BIOS and Grub as bootloader. If you would like to have explanation for other type of configuration, with UEFI for instance, please let a comment to request such article.</strong></p>

<h2>Power on : BIOS POST execution</h2>

<p>When you switch on your computer, the processor doesn&rsquo;t know anything about its environment. So it will executes the instruction located in a predefined memory location (<code>FFFF:0000h</code> in X86 based computers).</p>

<p>The instructions will redirect to another memory location, which is mapped to the <strong><a href="https://en.wikipedia.org/wiki/BIOS">BIOS</a> memory</strong>.</p>

<p>Indeed, when booting, the processor runs in a mode called <strong>real mode</strong>. In this mode, the processor access directly the memory via addresses starting from 0 to 1MB (<code>0xFFFFF</code>). But this memory is not mapped entirely to the <em><a href="https://en.wikipedia.org/wiki/RAM">RAM</a></em> memory. Some addresses are mapped to the <em>BIOS memory</em>, and other to the <em>legacy video card memory</em>.</p>

<p>The BIOS instructions will then be executed.</p>

<p><img src="http://pierre-jean.baraud.fr/images/linux/boot_00.png"></p>

<p>The first BIOS action is the <strong>POST (Power On Self Test)</strong>. The POST will check the presence and integrity of a set of important hardware devices, and inform you if it detect defects (with a series of <em>bip</em> sound).</p>

<h2>Reading the CMOS and choose the bootable device</h2>

<p>You cannot modify the BIOS instructions by yourself (without flashing it), but in order to save some information (time, user preferences), the motherboard is shipped with a memory called <em>CMOS</em>.</p>

<p>The CMOS will contains for instance an ordered list for the bootable devices.
The BIOS will check the presence of each device from this list, and also if it contains a bootable media.</p>

<p><img src="http://pierre-jean.baraud.fr/images/linux/boot_01.png"></p>

<p>Let&rsquo;s say that the bootable media is a hard drive for the rest of the explanation.</p>

<h2>Grub stage 1</h2>

<p>A hard drive contains a limited space in their first sector called <strong>Master Boot Record (MBR)</strong>. This MBR contains only 512 Bytes. And in theses 512 Bytes must enter:</p>

<ul>
<li>The instructions to boot the system (446 Bytes)</li>
<li>The information about the partitions of the hard drive (64 Bytes)</li>
<li>A checksum to verify the integrity of the MBR, called <em>Magic Number</em> (2 Bytes)</li>
</ul>


<p>The fact that the MBR is so small will lead to many difficulties: will the code to load the Linux kernel fit in this 446 Bytes? This limited size is also the reason why you can only have 4 primary partitions (4 descriptions of 16 Bytes), limited to 8GB or 2TB depending on the method they are described (<em>CHS</em> vs <em>LBA</em>).</p>

<p><img src="http://pierre-jean.baraud.fr/images/linux/boot_02.png"></p>

<p>To solve that, the boot process is done in several steps. The first step will load the instructions from the 446 Bytes length <strong>primary boot loader code</strong> and execute it. This is called the Grub Stage 1. <strong><a href="https://www.gnu.org/software/grub/">GRUB</a></strong> is what we called a <em>boot loader</em>.</p>

<h2>Grub stage 1.5</h2>

<p>The partitions start at sector 63. The MBR is written in sector 0. This area between the MBR and the beginning of partitions is called <strong>MBR GAP</strong>. GRUB uses this space to put some extra code in it.</p>

<p>The code in <em>GRUB stage 1</em>, doesn&rsquo;t know how to read a Linux partition, and as a consequence load the kernel image that is inside. That&rsquo;s why the <em>GRUB stage 1</em> load the content of the <em>MBR GAP</em>, which contains instructions for opening a Linux partition.</p>

<p><img src="http://pierre-jean.baraud.fr/images/linux/boot_03.png"></p>

<p>The execution of the code of the <em>MBR GAP</em> is called <strong>Grub stage 1.5</strong>.</p>

<h2>Grub stage 2</h2>

<p>But a part of the Grub configuration is modified by the user in configuration files located inside the Linux partition. That&rsquo;s why <em>Grub stage 1.5</em> needs to open the partition (the one that is called <em>active</em>) and read the file <code>/boot/grub/grub.cnf</code>.</p>

<p><img src="http://pierre-jean.baraud.fr/images/linux/boot_04.png"></p>

<p>When this is done, the Grub is in <em>stage 2</em>, and can prompt an interface to let the user make choices (such as choosing which kernel to load or add boot options parameters).</p>

<h2>Kernel Boot execution</h2>

<p>The Linux kernels are located in the <code>/boot</code> folder, and have name such as <code>vmlinuz-x.xx.x-xx-[...]</code>. These kernels are compressed files, that contains a <em>generic</em> core Linux kernel (if you didn&rsquo;t build it yourself). As this kernels have been generated by other people, who don&rsquo;t know the specificity of your configuration, some modules (as drivers) can be missing.</p>

<p>That&rsquo;s why you can also find in the <code>/boot</code> folder image called <code>initrd.img-x.xx.x-xx-[...]</code>. An <em>initrd</em> file is a temporary file-system that will be mounted during the boot process, and that will load the missing modules in the kernel. It allows to keep the kernel images small and to load dynamically only what is needed.</p>

<p><img src="http://pierre-jean.baraud.fr/images/linux/boot_05.png"></p>

<p>The vmlinuz files are executables files, that are actually composed of different chunks (<code>bootsect.o</code> + <code>setup.o</code> + <code>misc.o</code> + <code>piggy.o</code>). The <code>piggy.o</code> contains the gzipped vmlinux file. The processor is still in <em>real mode</em> which mean it can only address a memory area of 1 MB. The problem is that the compressed image is bigger than 1 MB. That&rsquo;s why the property of <em>bzImage</em> that allows to split the image in discontinuous area is convenient here. The <code>piggy.o</code> chunk is loaded outside the 1MB area zone (by switching the processor to protected mode), and the <code>bootsect.o</code>, <code>setup.o</code>, and <code>misc.o</code> will be load in the <em>real mode</em> map area.</p>

<p>The <code>bootsect.o</code> contains a legacy code that is now ignored (used to be the bootloader code for the <em>MBR</em>), and <code>setup.o</code> and <code>misc.o</code> initialize some variables and configuration (memory, video). After that the CPU pass into <strong>protected mode</strong>.</p>

<p>In <em>protected mode</em>, the CPU can address up to 4GB of memory, and can finally execute the <code>decompress_kernel()</code> instruction, that will uncompress the kernel image and mount the system layout, for finally launch the <strong>init process</strong>.</p>

<p>The <strong>init</strong> process is the first process launched in user space, and has the responsibility to launch all other needed services.</p>

<p>Historically, it was the <strong><a href="https://en.wikipedia.org/wiki/Sysvinit">SysVinit</a></strong> that did this job, but some distribution use <strong><a href="https://en.wikipedia.org/wiki/Upstart">Upstart</a></strong>, or the new <strong><a href="https://en.wikipedia.org/wiki/Systemd">Systemd</a></strong>. All these solutions work really differently (and would deserve a dedicated article), but they all get the same job done: launching all other needed user processes to start the system.</p>

<h2>Sources</h2>

<p>I based my understanding of the boot process from these great articles:</p>

<ul>
<li><a href="http://www.dewassoc.com/kbase/hard_drives/master_boot_record.htm">The Master Boot Record by Dewassoc</a></li>
<li><a href="http://www.slashroot.in/linux-booting-process-step-step-tutorial-understanding-linux-boot-sequence">Linux Booting Process by Slashroot</a></li>
<li><a href="http://duartes.org/gustavo/blog/post/kernel-boot-process/">Kernel Boot Process by Gustavo Duarte</a></li>
</ul>


<p>And also thanks to many articles of <a href="https://en.wikipedia.org">Wikipedia</a> and answers of the <a href="https://unix.stackexchange.com/">Unix and Linux StackExchange</a> community.</p>

<p>For any opinion, correction or question, feel free to comment!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hosting Docker Containers]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/06/02/host-docker-containers/"/>
    <updated>2014-06-02T09:52:40+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/06/02/host-docker-containers</id>
    <content type="html"><![CDATA[<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/host-solutions.png"></p>

<p>I already wrote about Docker, and today I will present different solutions to host your lovely docker containers. If you  want to know more about Docker, you can read <a href="http://pierre-jean.baraud.fr/blog/categories/docker/">my previous post on this subject</a>.</p>

<!-- More -->


<h2>Dedicated servers</h2>

<p>If you already have a dedicated server (hosted in a data center or just a home server), you can just install docker on it, and setup a proxy (nginx, apache, etc.) to redirect the requests to the right local port according to the domain.</p>

<p>You can do this in a static way or use the <a href="http://docs.docker.io/use/ambassador_pattern_linking/">ambassador pattern as presented here</a>. The static method is the simplest if you only manage a few containers, but if you want a robust environment to deploy a large amount of containers, you should have a look on how to deploy ambassador containers.</p>

<p>Instructions for installing Docker on several distributions are available in the <a href="http://docs.docker.io/installation/">official documentation</a>. For instance, on Ubuntu 14.04, you can install it directly from the package manager:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo apt-get update
</span><span class='line'>$ sudo apt-get install docker.io
</span><span class='line'>$ sudo ln -sf /usr/bin/docker.io /usr/local/bin/docker</span></code></pre></td></tr></table></div></figure>


<p>Then, you can build and run your containers, as explained in my previous posts. If you don&rsquo;t have any firewall blocking the port, your containers should already be accessible from the net.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/docker-host-direct.png"></p>

<p>Nevertheless, you may want to access your containers and their service by the default port. You can do this with a simple HTTP reverse proxy, or if you have only one container running for a specified service, you can map them directly to the host default port for this service.
The command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo  docker run -p 22:22 ssh-image /usr/sbin/sshd -D</span></code></pre></td></tr></table></div></figure>


<p>will launch the container based on image <em>ssh-image</em> and will map the port 22 of the container to the port 22 of the host.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/docker-host-proxy.png"></p>

<p>I won&rsquo;t enter into technical details in this post, but you can find a lot of resources on the net about how to setup a reverse proxy..</p>

<p>This solution is maybe the first one you will try, at least for experiencing with docker.</p>

<p><strong> Pros and cons:</strong></p>

<ul>
<li><p><em>Difficulty:</em> Even if installing Docker isn&rsquo;t difficult, maintaining a dedicated server could really end up in many headaches. You will have to manage upgrades, security issues, problems and configurations by yourself. Don&rsquo;t underestimate this part, especially if it&rsquo;s not your specialty.</p></li>
<li><p><em>Scalability:</em> You&rsquo;re on your own. If you already thinked this through and designed a nice solution to scale your services, it can work pretty good. Or fail terribly.</p></li>
<li><p><em>Price:</em> If you use your server 100% of its capacity, this may be the cheapest solution. Dedicated server are quite expensive, but you will also have a large amount of power to manage several services on the same machines.</p></li>
</ul>


<h2>Virtual Machines and VPS</h2>

<p>This is exactly the same principle than before, except that you are running on a virtual machine. If you don&rsquo;t need the power of a dedicated machine, this solution gives you (more or less) the same freedom as the previous one but for a really cheaper price. This is also true with any IAAS solution (<em>Infrastructure as a Service</em>, for instance: Amazon EC2, Google Compute Engine, etc.). If you use a PAAS (Platform as a service) solution, you have to check if you can run docker containers on it, which, for the moment, is unlikely.</p>

<p><strong>Pros and cons:</strong></p>

<ul>
<li><em>Difficulty:</em> The same as the dedicated server; you will have to setup the platform by yourself.</li>
<li><em>Scalability:</em> You may be able to find it a little bit easier to scale with VM, but you will have to think your scalabitlity solution by yourself, just like with dedicated.</li>
<li><em>Price:</em> Cheaper than a dedicated server, as you only use the power you need. You may even find IAAS solution that let you pay according to the cpu power used or the time your server is up (per minutes).</li>
</ul>


<h2>DigitalOcean</h2>

<p><a href="https://www.digitalocean.com">DigitalOcean</a> is a hosting company, that offers virtual machines with preinstalled environments designed for developers.</p>

<p>You can setup really easily what they call a <em>droplet</em>, which is a KVM instance running on SSD hard drive with more or less CPU and storage depending on the pricing solution.</p>

<p>What is cool is that they offer to setup machines with docker already installed. The design of the website is clear and nice, and the pricing policy flexible.</p>

<p>Let&rsquo;s see how to create a droplet with Docker installed.</p>

<p>First of all <strong><a href="https://cloud.digitalocean.com/registrations/new">Sign up</a></strong>. They will ask you your credit card information, so that you can create droplet as soon as the process is finished.</p>

<p>Then <strong><a href="https://cloud.digitalocean.com/login">log in</a></strong>, and click on <strong>Create Droplet</strong>.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/digitalocean-screen01.png"></p>

<p>You give a name to the droplet (the name doesn&rsquo;t really matter, it&rsquo;s just for you):</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/digitalocean-screen02.png"></p>

<p>And select the type of droplet you need. As you can see, prices start at 5$/month or 0.007$/hour for a basic configuration (1 CPU/512GB RAM/20GB SSD) to 640$/month or 0.952$/hour for the most powerfull configuration (20 CPU/64GB RAM/640GB SSD). Let&rsquo;s select the basic configuration: you can delete it whenever you want after this test, and it will just cost a few cents.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/digitalocean-screen03.png"></p>

<p>You select the region of your droplet. For the moment are available: New York, San Francisco, Amsterdam and Singapore.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/digitalocean-screen04.png"></p>

<p>You can install an OS distribution but also an image with applications already installed. Let&rsquo;s click on Applications and select Docker. They provide the latest Docker release available, which is nice.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/digitalocean-screen05.png"></p>

<p>Finally, you can choose to add a previously saved SSH Key, if you have one.</p>

<p>Once everything is selected, click <strong>Create Droplet</strong>.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/digitalocean-screen06.png"></p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/digitalocean-screen07.png"></p>

<p>The Droplet is set up in less than a minute. The root password will be emailed to you if you don&rsquo;t have associate any SSH Key with the droplet.
The IP of the machine is displayed just after its creation.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/digitalocean-screen08.png"></p>

<p>You can ssh into the machine and launch directly your docker containers!</p>

<p>DigitalOcean provide a nice and clear interface, you can interact with it through <a href="https://developers.digitalocean.com/">their REST API</a>, the prices are cheap and flexible.</p>

<h2>Tutum</h2>

<p>If you are really looking for a platform dedicated to Docker, there is <a href="http://www.tutum.co/">Tutum</a>.
Tutum is a &ldquo;Container-as-a-service&rdquo;, and is the simplest solution to run docker containers that I&rsquo;ve seen.</p>

<p>Let&rsquo;s see how to setup and run a container in Tutum.</p>

<p>First of all, <strong><a href="https://app.tutum.co/accounts/register/">sign up</a></strong>, you will notice that no credit card information will be asked. Indeed, you can create your first container for free for a month, which is a great way to test the platform. You&rsquo;ll see some warnings alerting that Tutum is still in beta, but Docker is also still in beta, so it shouldn&rsquo;t be an issue, as you shouldn&rsquo;t use Docker in production for the moment.</p>

<p>Once you are <a href="https://app.tutum.co/">logged in</a>, click on <strong>Launch your first application</strong>.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/tutum-screen01.png"></p>

<p>You can choose one of the preset docker images to start with&hellip;</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/tutum-screen02.png"></p>

<p>or choose from the official docker index or any other registry.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/tutum-screen03.png"></p>

<p>And if you want to keep your images private, Tutum provide a <a href="http://docs.tutum.co/features/registry/">private registry</a> where you can push your docker images!</p>

<p>Let&rsquo;s try the wordpress default image!</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/tutum-screen04.png"></p>

<p>Once selected, you can choose a name for your container, the tag (version) of the image, and the resources allocated to the container. It goes from $4/month (0.25 CPU ECU/256MB) to $64/month (4 CPU ECU/4GB Memory). Let&rsquo;s try the XS Solution (free for a month).
Click on <strong>Launch</strong>.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/tutum-screen05.png"></p>

<p>In just a few seconds, the container is setup and ready to use.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/tutum-screen06.png"></p>

<p>When you click on your container, you find directly the exposed port, and a link to the application.</p>

<p><img src="http://pierre-jean.baraud.fr/images/docker/tutum-screen07.png"></p>

<p>If you click on it, <em>tadaaam</em>, your site is ready and waiting for you.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/tutum-screen08.png"></p>

<p>With Tutum, you manage directly your docker containers, without worrying about any infrastructure issue. It provides dedicated screen for Logs, Environment variables and monitoring. It also provides a <a href="http://docs.tutum.co/reference/api/">REST API</a> to interact with your containers. And if you want to use a custom domain, You can also setup it when you create your container.</p>

<p>The interface is neat and clear, and you can scale your services really easily. The prices are fair regarding the services they provide (scaling, load balancing, web proxies). It is really enjoyable to deploy so easily any docker images in the cloud in a few seconds.</p>

<p>And you, how do you deploy your docker containers?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Deeper Look Into Dockerfiles]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/05/19/deeper-look-dockerfile/"/>
    <updated>2014-05-19T16:18:54+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/05/19/deeper-look-dockerfile</id>
    <content type="html"><![CDATA[<p>I introduced in <a href="http://pierre-jean.baraud.fr/blog/2014/05/14/fist-look-dockerfile/">a previous post</a> how to create <a href="https://www.docker.io/">Docker</a> images interactively and with a <em>Dockerfile</em>.</p>

<p>In this post, I will focus on good practices and see how a proper repository is realized. Indeed, in my previous post, my example was a little bit trivial, and if you want to create your own images through a Dockerfile, you will surely bump into difficulties: how do I manage interactive installation that ask a user input during install? How should I configure my application after installation? And many others&hellip;</p>

<!-- More -->


<h2>Trusted Builds: a good way to learn</h2>

<p>When you commit your image in a local repository, or push it into a remote repository, you only push the built image, as a file.
Trusted build is a mechanism to build automatically an image from its sources: the docker index will built the image each time a commit is done on the public github repository corresponding to the docker image.
This is a great way to study popular images and see how their maintainers manage difficulties you can have with the settings of some images.</p>

<p>You can browse and search into the official Docker index of repositories from the <a href="https://index.docker.io/">website</a>, or interact with it in command line with <code>docker search</code>, <code>docker pull</code> and <code>docker push</code>.
Let&rsquo;s have a look to the <em>mysql</em> image of the repository <em>tutum</em> (provided by <a href="http://tutum.co">tutum.co</a>), available <a href="https://index.docker.io/u/tutum/mysql/">here</a>. As it is a trusted build, you have access to the <a href="https://github.com/tutumcloud/tutum-docker-mysql">github page</a> from where the image is built.</p>

<p><strong>Erratum: the repository has changed since the date of this post, I let the information available here, but you may find differences with the sources hosted on Github.</strong></p>

<h2>Dockerfile</h2>

<p>Let&rsquo;s have a look the docker file, and the good practices it includes.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM ubuntu:trusty
</span><span class='line'>MAINTAINER Fernando Mayo &lt;fernando@tutum.co>
</span><span class='line'>
</span><span class='line'># Install packages
</span><span class='line'>RUN apt-get update
</span><span class='line'>RUN DEBIAN_FRONTEND=noninteractive apt-get -y install supervisor mysql-server pwgen
</span><span class='line'>
</span><span class='line'># Add image configuration and scripts
</span><span class='line'>ADD start.sh /start.sh
</span><span class='line'>ADD run.sh /run.sh
</span><span class='line'>ADD supervisord-mysqld.conf /etc/supervisor/conf.d/supervisord-mysqld.conf
</span><span class='line'>ADD my.cnf /etc/mysql/conf.d/my.cnf
</span><span class='line'>ADD mysqld_charset.cnf /etc/mysql/conf.d/mysqld_charset.cnf
</span><span class='line'>ADD create_mysql_admin_user.sh /create_mysql_admin_user.sh
</span><span class='line'>ADD import_sql.sh /import_sql.sh
</span><span class='line'>RUN chmod 755 /\*.sh
</span><span class='line'>
</span><span class='line'>EXPOSE 3306
</span><span class='line'>CMD ["/run.sh"]</span></code></pre></td></tr></table></div></figure>


<h3>FROM command</h3>

<p>The FROM command defines the base image for this image.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM ubuntu:trusty</span></code></pre></td></tr></table></div></figure>


<p>You can see that the maintainer used a tag to define precisely which version of Ubuntu to use. <strong>You should always define a tagged version of your base image</strong> to precisely define which release of the distribution your image relies on.</p>

<h3>MAINTAINER</h3>

<p>The maintainer is vital tag, to define the author of the image and a way to contact it.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MAINTAINER Fernando Mayo &lt;fernando@tutum.co></span></code></pre></td></tr></table></div></figure>


<h3>COMMENTS</h3>

<p>You can add comments with the character <code>#</code>. You should always add comments to explain the goal of each block of instructions.</p>

<h3>RUN command</h3>

<p>After each <code>RUN</code> instruction, the image is committed, and the following RUN instruction is executed on the newly committed image.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Install packages
</span><span class='line'>RUN apt-get update
</span><span class='line'>RUN DEBIAN_FRONTEND=noninteractive apt-get -y install supervisor mysql-server pwgen</span></code></pre></td></tr></table></div></figure>


<p>We can notice several practices here:</p>

<ul>
<li><p>No usage of <code>apt-get upgrade</code>: Indeed, you just want to add on this layer what is needed for the container. If you want to upgrade the system, you should <strong>upgrade the base image</strong>, as it is its role to offer the system environment.</p></li>
<li><p>Avoid interaction: the <code>RUN</code> command is <strong>executed in a non-interactive way</strong>. As a consequence, you don&rsquo;t want to been ask for confirmation when installing package: you must use the <code>-y</code> option in <code>apt-get install -y &lt;packages&gt;</code>. Moreover some packages ask questions during installation about account creation, default configuration, etc. It is the case for mysql-server for instance. That&rsquo;s why the author put the variable <code>DEBIAN_FRONTEND</code> to <code>noninteractive</code>, in order to inform that there won&rsquo;t be any interaction during installation.</p></li>
<li><p>Finally, there is the <code>apt-get update</code>. It is the most litigious command. If you install your packages via <code>apt-get</code>, you have no choice but to update the index of packages before the install: you don&rsquo;t want to have an outdated cache and broken links during installation. Nevertheless, it also means that the Dockerfile can create slightly different images depending of the date of build. Indeed, the version of a package or a dependency of a package you want to install can have change in the repository. The only work around is to install your packages via a direct link to a binary package or from source. Anyway, the consequence can be neglected as you don&rsquo;t want to rebuild your image every day, and you should build it once and use it / share it as long as you want to use the same environment.</p></li>
</ul>


<h3>ADD command</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Add image configuration and scripts
</span><span class='line'>ADD start.sh /start.sh
</span><span class='line'>ADD run.sh /run.sh
</span><span class='line'>ADD supervisord-mysqld.conf /etc/supervisor/conf.d/supervisord-mysqld.conf
</span><span class='line'>ADD my.cnf /etc/mysql/conf.d/my.cnf
</span><span class='line'>ADD mysqld_charset.cnf /etc/mysql/conf.d/mysqld_charset.cnf
</span><span class='line'>ADD create_mysql_admin_user.sh /create_mysql_admin_user.sh
</span><span class='line'>ADD import_sql.sh /import_sql.sh</span></code></pre></td></tr></table></div></figure>


<p>The maintainer has added two types of external files here:</p>

<ul>
<li><p><strong>Configuration files</strong>: you want your image to be operational immediately after the build. You have to provide working default configurations that allow to use the package in rational conditions. You must of course allow the user to override the configuration settings (by adding its own configuration files, or with environment variables).</p></li>
<li><p><strong>Scripts files</strong>: As you want to automate all setup steps, it is a good idea to wrap your launcher inside scripts that could executes some  checking and actions for you (<em>Database creation</em>, <em>Account creation</em>, etc.).</p></li>
</ul>


<h3>EXPOSE command</h3>

<p>The Dockerfile defines the ports you want to expose to the host system to access the service you will run on the container, with the instruction <code>EXPOSE</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>EXPOSE 3306</span></code></pre></td></tr></table></div></figure>


<p>Even if you can tell on which host port you want to map the local port, this is good practice to let Docker framework dynamically map the port to the host. Indeed, if you map yourself the port, you won&rsquo;t be able to launch several containers from the same Dockerfile, as the first one will lock the port for itself.</p>

<h3>CMD command</h3>

<p>Finally, you can tell Docker which process it should execute by default when launching a container.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CMD ["/run.sh"]</span></code></pre></td></tr></table></div></figure>


<p>Here, as the maintainer wrapped the process into a script to automate account creation, it launches the script instead of the process.</p>

<h2>Supervisor</h2>

<p>If you study the scripts, you may have noticed that the maintainer doesn&rsquo;t launch the mysql server directly, but launch instead a process called <strong>Supervisord</strong>. <a href="http://supervisord.org/">Supervisor</a> is a process control system, a little bit like <code>init</code>, that allow you to manage the execution of several processes.</p>

<p>Indeed, I told you in my previous article that a Docker container can only run one job: there isn&rsquo;t any <code>init</code> running instance to manage the lifecycle of several process executions in a Docker container. Nevertheless, you will certainly want to be able to manage several processes or job in a same container: for example, running a SSH server and at the same time another kind of server. You can use Supervisor to do that.</p>

<p>Better, as explained in this <a href="http://blog.trifork.com/2014/03/11/using-supervisor-with-docker-to-manage-processes-supporting-image-inheritance/">article</a>, you can use inheritance to include the Supervisor configuration files from you base image, to launch the services the base image already provide in parallel with the jobs you define in your own configuration.</p>

<h2>README.md</h2>

<p>Finally, the author of the image included a README.md explaining how to build, launch and configure the container. It is really handy and you always should include it if you create your own trusted build. The README is displayed on the<a href="https://index.docker.io/u/tutum/mysql/"> Docker index website</a> when you look for the image.</p>

<h2>What&rsquo;s next?</h2>

<p>You have seen how is built a popular docker image. If you want to create your own Docker image, you should search for similar images in the Docker index and analyze their Dockerfiles. All trusted build are available through their github page, so it&rsquo;s a really easy task.</p>

<p>I hope this post will help you to create great images for yourself and the community!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A First Look Into Dockerfiles]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/05/14/fist-look-dockerfile/"/>
    <updated>2014-05-14T13:45:54+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/05/14/fist-look-dockerfile</id>
    <content type="html"><![CDATA[<p>A <a href="http://pierre-jean.baraud.fr/blog/2014/05/07/docker/">week ago</a>, I introduced the framework <a href="http://docker.io">Docker</a>. Docker is a lightview virtualized environment. It allows to build, manage and run containers to easily deploy an app in an iso environment.
I will introduce today how to create containers interactively and through Dockerfile.</p>

<!-- More -->


<h2>Hands on containers and images</h2>

<p>If you&rsquo;re not familiar with Docker, I strongly recommend you to have a look to their <a href="https://www.docker.io/gettingstarted/#">interactive tutorial</a>. It is well done, efficient, and get you into the swing of things. The <a href="https://www.docker.io/learn/dockerfile/">Dockerfile tutorial</a> will also give you all the basis. I will try here to sum up the more important concepts.</p>

<h3>What is a container?</h3>

<p>A container can be represented by two main components:</p>

<ul>
<li>A running job</li>
<li>A filesystem modified by the job</li>
</ul>


<p>The filesystem itself is a multilayered union filesystem, with the top layer saving the current modifications, and the underlying layers read only images. Let&rsquo;s have a deeper look on what is a multilayered union filesystem.</p>

<h3>Images and AUFS</h3>

<p>Let&rsquo;s build our own customized image! First of all, let&rsquo;s pull an image from the docker index.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker pull ubuntu:precise</span>
</span></code></pre></td></tr></table></div></figure>


<p>This will download an image with the files of Ubuntu Precise distribution (without the Kernel, as it uses the host kernel).</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/docker-image-creation-00.png"></p>

<p>You can have information about downloaded images with the command <code>docker images</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="gp">$</span> sudo docker images
</span><span class='line'><span class="go">REPOSITORY           TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span>
</span><span class='line'><span class="go">ubuntu               precise             74fe38d11401        3 weeks ago         209.6 MB</span>
</span></code></pre></td></tr></table></div></figure>


<p>We will then interact with it by launching a job from this filesystem.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker run ubuntu:precise apt-get install -y memcached</span>
</span><span class='line'><span class="go">[...]</span>
</span></code></pre></td></tr></table></div></figure>


<p>When executing this command, we create a container. This container will create a writable layer for its filesystem, and base it upon the image <em>ubuntu:precise</em>. It will then launch the process <code>apt-get</code> with the argument <code>install -y memcached</code></p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/docker-image-creation-01.png"></p>

<p>I didn&rsquo;t affect any name to the container in the previous command. To find the id of a running container, you can type the command <code>docker ps</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker ps</span>
</span><span class='line'><span class="go">CONTAINER ID        IMAGE               COMMAND                CREATED              STATUS              PORTS               NAMES</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here, I don&rsquo;t have any running container. Indeed, the status of the container is related to the status of its running job. As a consequence, once <code>apt-get install -y memcached</code> returned, the container is stopped.</p>

<p>To display all containers currently on your machine, you can type <code>docker ps -a</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker ps -a</span>
</span><span class='line'><span class="go">CONTAINER ID        IMAGE               COMMAND                CREATED              STATUS              PORTS               NAMES</span>
</span><span class='line'><span class="go">cab24787db86        ubuntu:12.04        apt-get install -y m   About a minute ago   Exit 0                                  clever_curie  </span>
</span></code></pre></td></tr></table></div></figure>


<p>I can now commit the content of the filesystem of this container into a new image:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker commit cab24</span>
</span><span class='line'><span class="go">9f97edd4e9ee794eca4c40db3122b5c635f0e2f92c3b0e62deaac9e28af1a868</span>
</span></code></pre></td></tr></table></div></figure>


<p>You will note that typing just the first digits of the id is enough to find it, as in git.</p>

<p>You image is now visible when you display your docker images:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker images</span>
</span><span class='line'><span class="go">REPOSITORY           TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span>
</span><span class='line'><span class="go">&lt;none&gt;               &lt;none&gt;              9f97edd4e9ee        3 minutes ago       246.2 MB</span>
</span><span class='line'><span class="go">ubuntu               precise             74fe38d11401        3 weeks ago         209.6 MB</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can run a new container based on this new image:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker run --name &quot;bash-on-mysql-image&quot; -i -t 9f97ed /bin/bash</span>
</span><span class='line'><span class="gp">root@1ddbe7cefb87:/#</span>
</span></code></pre></td></tr></table></div></figure>


<p>You will now run a new container, with the process <code>/bin/bash</code>, <code>-i</code> and <code>-t</code> options for respectively running it interactively and attaching a pseudo  tty, <code>--name</code> to name our container, that will put a writable layer upon our image 9f97edd, which is itself based on our images ubuntu:precise.</p>

<p><img class="center" src="http://pierre-jean.baraud.fr/images/docker/docker-image-creation-03.png"></p>

<p>You may have understand now that referencing the images by their id won&rsquo;t be handy, That&rsquo;s why you will prefer to organize your images under</p>

<p>If you want to organize your images, it is better to commit them under your local repository.
You could have run this command to commit from the container:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker commit 9f97e yabage/ubuntu-memcached</span>
</span></code></pre></td></tr></table></div></figure>


<p>Or you can tag the current image directly</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker tag 9f97e yabage/ubuntu-memcached</span>
</span></code></pre></td></tr></table></div></figure>


<h2>The Dockerfile</h2>

<p>You have seen how to build an image by interacting directly with the container. Nevertheless, most of the time you will want to share your images through &ldquo;recipes&rdquo; allowing others to <strong>build</strong> themselves your images.
This is what <strong>Dockerfiles</strong> are for.</p>

<p>The Dockerfile lists the instruction on how to build your image and what to run on the container.</p>

<p>As you want to obtain the same image in every circumstances, you will have to <strong>avoid</strong> any operation that <strong>doesn&rsquo;t result in a controlled and guaranted state</strong>. For instance, you should not do any <code>apt-get upgrade</code> in a Dockerfile, as you don&rsquo;t controlled the result : indeed, depending the date your launching it, the upgrade could be different. Moreover, for technical reasons, there is a high chance that the upgrade fails. If you want to upgrade your distribution, you should update the base image your Dockerfile rely on.</p>

<p>Now let&rsquo;s see how to build the first container in a Dockerfile:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM ubuntu:precise #the base image of this build script
</span><span class='line'>
</span><span class='line'>RUN apt-get install -y memcached</span></code></pre></td></tr></table></div></figure>


<p>Well&hellip;that&rsquo;s all. You know have a container with memcached installed.</p>

<p>I kept this Dockerfile minimalistic on purpose, but you will want to define the maintainer of the Dockerfile with the tag <code>MAINTAINER</code>, define the default process to launch with <code>CMD</code> and a lot of other useful instructions.
For now I will stick to this version.</p>

<p>I would like to focus your attention on a point: each RUN instruction will commit the current layer and create a new one upon it. <strong>The state of the memory is forgotten</strong> between two <code>RUN</code> instructions. Only the filesystem is kept.</p>

<p>To build an image, you put these instructions in a file called <em>Dockerfile</em>, then execute the <code>build</code> command from the same folder:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">sudo docker build .</span>
</span></code></pre></td></tr></table></div></figure>


<p>It will build the container and return its id. If you want to name the container when building, you can do it with the <code>-t</code> option</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">sudo docker build -t ubuntu-memcached .</span>
</span></code></pre></td></tr></table></div></figure>


<p>You have seen a very quick introduction to Dockerfile. I will soon write an article about how to write a proper Docker image, following good practices, so that you can share them with your friends and the community!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction to Isometric 3D]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/05/13/3d-iso-introduction/"/>
    <updated>2014-05-13T16:09:50+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/05/13/3d-iso-introduction</id>
    <content type="html"><![CDATA[<p><img class="center" src="http://pierre-jean.baraud.fr/images/iso/iso-result-mini.png" title="" ></p>

<p>You want to create a nice graphic presentation, but you don&rsquo;t know anything about design? You need to create some game graphic elements, but you&rsquo;re really bad at drawing?</p>

<p>Isometric 3D allows you to create really neat and fun elements without knowing anything about design or art. In a few steps you can obtain really nice results.</p>

<!-- More -->


<h2>A simple square</h2>

<p>Let&rsquo;s try to create a square in isometric projection.</p>

<h3>The editor</h3>

<p>I will use the great vector graphics editor <a href="http://www.inkscape.org/">Inkscape</a>, that I have been fond of for years.
Inkscape is free, open-source, multi-platform (Windows, Mac, Linux) and uses the standard format SVG. Many browser can open directly SVG files.</p>

<p>Vector graphics allows you to draw &ldquo;shapes&rdquo; instead of &ldquo;pixels&rdquo;, so you can zoom infinitely without losing precision. Another well known vector graphic editor is Adobe Illustrator.</p>

<p>My instructions will be for Inkscape, but the principles can be applied in any other vectorial or bitmap editor.</p>

<h3>Simple square</h3>

<p>Let&rsquo;s see how to draw a simple square in isometric projection. Open Inkscape and follow these instructions:</p>

<ul>
<li>Select the <strong>rectangle tool</strong> on the left (<strong>F4</strong> on Linux)</li>
<li>Maintain the key <strong>Ctrl</strong> pressed and draw the square. <em>Ctrl</em> will maintain proportions to obtain a square.</li>
</ul>


<p> <img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-01.png"></p>

<ul>
<li>Then, select the <strong>shape edition tool</strong> (<strong>F2</strong>) or click once in your square to enable the shape modification.</li>
<li>Select the upper node and while maintaining <strong>Ctrl</strong> key, skew the square 2 steps to the right. Another method is using the Transform dialog (menu <strong>Object/Transform</strong> or <strong>Shift+Ctrll+M</strong>) and skew horizontally by 30°.</li>
</ul>


<p> <img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-02.png"></p>

<ul>
<li>Finally, Select again the <strong>shape edition tool</strong> (<strong>F2</strong>), and while maintaining the <strong>Ctrl</strong> key, rotate 2 steps to the right. Another method is to use the Transform dialog and rotate by 30°.</li>
</ul>


<p> <img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-03.png"></p>

<p>You now have a nice square in isometric perspective.</p>

<h3>Add Text</h3>

<p>All transformation done to the square can be applied to text too. As a consequence following previous steps:</p>

<ul>
<li>Select <strong>Text tool</strong> (<strong>F8</strong>), and write something.</li>
</ul>


<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-04.png"></p>

<ul>
<li>Skew to the right by 30°.</li>
</ul>


<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-05.png"></p>

<ul>
<li>Rotate to the right by 30°</li>
</ul>


<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-06.png"></p>

<p>You now have shapes and text on the same perspective.</p>

<h3>Add other faces</h3>

<p>By changing the direction of skew or rotation, you can add shapes on the 2 others plans of isometric projection.</p>

<ul>
<li>Create another rectangle</li>
</ul>


<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-07.png"></p>

<ul>
<li>Skew it to the left this time</li>
</ul>


<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-08.png"></p>

<ul>
<li>Rotate it to the right</li>
</ul>


<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-09.png"></p>

<ul>
<li>Notice that if you want to resize your square once on a isometric plan, you can use the square tool once your square selected (or press <strong>F4</strong>) and you&rsquo;ll be able to resize it in the plan by grabbing the corners.</li>
</ul>


<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-10.png"></p>

<ul>
<li>You do the same with the other rectangle, but by skewing it to the right and rotating it to the left</li>
</ul>


<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-11.png"></p>

<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-12.png"></p>

<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-screen-13.png"></p>

<p>By playing with the colors of the different squares, you can obtain a nice impression of volume, without effort or knowledge.</p>

<h3>Be creative</h3>

<p>You can apply this to disc shapes as well and create complete world in isometric projection!</p>

<p><img src="http://pierre-jean.baraud.fr/images/iso/iso-example.png"></p>

<p>Be aware, though, that this method isn&rsquo;t an efficient way to create graphs for report. You can find many specialized tools dedicated to this task. But by drawing from scratch you have a total freedom on the result. Your imagination is your only limit!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Train Your Java Skills]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/05/12/train-your-skills/"/>
    <updated>2014-05-12T20:04:02+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/05/12/train-your-skills</id>
    <content type="html"><![CDATA[<p>Want to train your Java developer skills? Having an interview to prepare? Just want to refresh your memory on theory or evaluate your current knowledge?</p>

<p>Here are some sites to help you.</p>

<!-- More -->


<h2>Questions sets</h2>

<p>You can find on internet many websites with some interview questions. Here are two I personally selected:</p>

<h3>Udemy Top 15 questions article</h3>

<p><a href="https://www.udemy.com/blog">Udemy</a> wrote an <a href="https://www.udemy.com/blog/java-interview-questions/">article about the top 15 questions</a> asked on Java interviews. This article presents really classic questions that you pretty sure to be asked about, or at least for which you should know the answer before going to an interview.</p>

<h3>JavaTpoint 170 core Java questions article</h3>

<p>If you want a more extended set of question than the previous article, you can read <a href="http://www.javatpoint.com/corejava-interview-questions">the 170 core Java questions article</a> by <a href="http://www.javatpoint.com/">JavaTpoint</a>.</p>

<p>This questions cover a large part of core Java (basic) knowledge, and they come with nicely written answers.</p>

<h2>Interactive problems</h2>

<p>Finally, a language knowledge is nothing if you don&rsquo;t master algorithms. <a href="https://codility.com/">Codility</a> is a website that aims to be used by companies to select candidates through coding exercices, but they provide <a href="https://codility.com/programmers/lessons/">a nice training section</a> where you can practices your skills on exercices and problems.</p>

<p><img src="http://pierre-jean.baraud.fr/images/app-screenshots/codility-screenshot.png"></p>

<p>It&rsquo;s free, and really well designed!</p>

<p>If you know any other source of training, feel free to share them!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Update OVH DynHost Address From Linux]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/05/09/update-ovh-dynhost-address-from-linux/"/>
    <updated>2014-05-09T20:45:39+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/05/09/update-ovh-dynhost-address-from-linux</id>
    <content type="html"><![CDATA[<p>I have my domain name registered at <a href="http://www.ovh.com">OVH</a>. To update a DNS address from a machine behind a dynamic IP, they provide a feature called <strong>DynHost</strong>. DynHost uses the same protocol as DynDNS for updating their website.</p>

<!-- More -->


<p>From your DNS Section of the <a href="https://www.ovh.com/managerv3">OVH manager webapp</a>, you can create a DynHost account: you will have to specify the DNS address you want to update, a username and password for this account.</p>

<p><strong>Warning</strong>: The script that update your DynHost address sends your login and password uncrypted! Don&rsquo;t use the same login/password as your main OVH Manager account.</p>

<p>Once created, you can configure your home server to update your DynHost.</p>

<h2>Configure Updatedd</h2>

<p>Updatedd is an utility recommended by OVH to update your address from Linux. You can find it <a href="http://nongnu.askapache.com/updatedd/updatedd_2.6.tar.gz">here</a>.</p>

<p>Get the sources:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ wget http://nongnu.askapache.com/updatedd/updatedd_2.6.tar.gz</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then, you will have to fix an error in a configuration file before compile it.
Extract and edit the libovh file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ tar xvf updatedd_2.6.tar.gz</span>
</span><span class='line'><span class="go">~$ nano updatedd-2.6/src/plugins/libovh.h</span>
</span></code></pre></td></tr></table></div></figure>


<p>And replace the host <strong>ovh.com</strong> on line 24 by <strong>www.ovh.com</strong>. You should have:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define DYNDNSHOST "www.ovh.com"</span></code></pre></td></tr></table></div></figure>


<p>We can now compile updatedd:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ ./configure</span>
</span><span class='line'><span class="go">~$ make</span>
</span><span class='line'><span class="go">~$ sudo make install</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can now use updatedd to update your domain name with the command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">updatedd ovh -- --ipv4 yourIP dynHostUsername:dynHostPassword host</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Automate the DynHost Update</h2>

<p>To update your account, create a script and run it on a daily base with cron.</p>

<p>Create a Script with this content:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'>
</span><span class='line'><span class="c">## dynhost parameters</span>
</span><span class='line'><span class="nv">username</span><span class="o">=</span>dynHostUser
</span><span class='line'><span class="nv">password</span><span class="o">=</span>dynHostPassword
</span><span class='line'><span class="nv">host</span><span class="o">=</span>yourmain.com
</span><span class='line'>
</span><span class='line'><span class="c">##Log (1=true,0=false)</span>
</span><span class='line'><span class="nv">log_change</span><span class="o">=</span>1
</span><span class='line'><span class="nv">log_no_change</span><span class="o">=</span>0
</span><span class='line'><span class="nv">log_file</span><span class="o">=</span>/var/log/dynhost.log
</span><span class='line'>
</span><span class='line'><span class="c">#File with old IP</span>
</span><span class='line'><span class="nv">old_ip_file</span><span class="o">=</span>/var/cache/ip_old
</span><span class='line'>
</span><span class='line'>touch <span class="k">${</span><span class="nv">old_ip_file</span><span class="k">}</span>
</span><span class='line'>touch <span class="k">${</span><span class="nv">log_file</span><span class="k">}</span>
</span><span class='line'>
</span><span class='line'><span class="c">#Get public IP</span>
</span><span class='line'><span class="nv">ip</span><span class="o">=</span><span class="s2">&quot;`dig +short myip.opendns.com @resolver1.opendns.com`&quot;</span>
</span><span class='line'><span class="nv">ip_old</span><span class="o">=</span><span class="sb">`</span>cat <span class="k">${</span><span class="nv">old_ip_file</span><span class="k">}</span><span class="sb">`</span>
</span><span class='line'>
</span><span class='line'><span class="c">#Compare IP</span>
</span><span class='line'><span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;${ip}&quot;</span> <span class="o">=</span> <span class="s2">&quot;${ip_old}&quot;</span> <span class="o">]</span>
</span><span class='line'><span class="k">then </span>
</span><span class='line'><span class="k">   if</span> <span class="o">[</span> <span class="s2">&quot;${log_no_change}&quot;</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span> <span class="o">]</span>
</span><span class='line'>   <span class="k">then</span>
</span><span class='line'><span class="k">      </span><span class="nb">echo</span> <span class="sb">`</span>date<span class="sb">`</span>: No IP change was found &gt;&gt; <span class="k">${</span><span class="nv">log_file</span><span class="k">}</span>
</span><span class='line'>   <span class="k">fi</span>
</span><span class='line'><span class="k">else</span>
</span><span class='line'><span class="k">   </span><span class="nb">echo</span> <span class="k">${</span><span class="nv">ip</span><span class="k">}</span> &gt; <span class="k">${</span><span class="nv">old_ip_file</span><span class="k">}</span>
</span><span class='line'>   <span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;${log_change}&quot;</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span> <span class="o">]</span>
</span><span class='line'>   <span class="k">then</span>
</span><span class='line'><span class="k">      </span><span class="nb">echo</span> <span class="s2">&quot;`date`:IP has changed. (Old : ${ip_old}, New : ${ip})&quot;</span> &gt;&gt; <span class="k">${</span><span class="nv">log_file</span><span class="k">}</span>
</span><span class='line'>      updatedd ovh -- --ipv4 <span class="k">${</span><span class="nv">ip</span><span class="k">}</span> <span class="k">${</span><span class="nv">username</span><span class="k">}</span>:<span class="k">${</span><span class="nv">password</span><span class="k">}</span> <span class="k">${</span><span class="nv">host</span><span class="k">}</span> &gt;&gt; <span class="k">${</span><span class="nv">log_file</span><span class="k">}</span>
</span><span class='line'>   <span class="k">else</span>
</span><span class='line'><span class="k">      </span>updatedd ovh -- --ipv4 <span class="k">${</span><span class="nv">ip</span><span class="k">}</span> <span class="k">${</span><span class="nv">username</span><span class="k">}</span>:<span class="k">${</span><span class="nv">password</span><span class="k">}</span> <span class="k">${</span><span class="nv">host</span><span class="k">}</span>
</span><span class='line'>   <span class="k">fi</span>
</span><span class='line'><span class="k">fi</span>
</span></code></pre></td></tr></table></div></figure>


<p>Don&rsquo;t forget to change DynHost parameters with yours in the script.</p>

<p>Make the script executable and put both updatedd and your script in a folder in your path. For instance:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ chmod +x yourscript </span>
</span><span class='line'><span class="go">~$ cp updatedd yourscript /usr/local/bin</span>
</span></code></pre></td></tr></table></div></figure>


<p>Finally, put into your cron so that it is executed on a daily base (here every 30 minutes):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo <span class="nb">echo</span> <span class="s2">&quot;30  *    * * *   root    your-script&quot;</span> &gt;&gt; /etc/crontab
</span></code></pre></td></tr></table></div></figure>


<p>The steps and scripts described here have been adapted from <a href="http://lermit-informatique.blogspot.de/2009/08/ovh-le-dynhost-de-ovh-et-updatedd.html">this article</a>.
This steps should work for any provider supporting DynDNS protocol.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Code and Play]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/05/08/code-and-play/"/>
    <updated>2014-05-08T19:46:08+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/05/08/code-and-play</id>
    <content type="html"><![CDATA[<p>Feel disconnected from the pleasure of code? Hacking is definitely less fun than what you expected as a teenager when watching Matrix?
Well, it&rsquo;s time to enjoy the fun of coding again, thanks to one of the projects I&rsquo;m going to present in this article!</p>

<h2>Untrusted, a meta-JavaScript adventure game</h2>

<p>Untrusted is a project developed by <a href="http://alex.nisnevich.com/portfolio/">Alex Nisnevich</a>, where you play in an ASCII art environment and interact in it with JavaScript code.</p>

<p><img src="http://pierre-jean.baraud.fr/images/gaming/untrusted-screenshot.png"></p>

<p>This project was acclaimed by the community, and it is well deserved! You can try it <a href="https://alexnisnevich.github.io/untrusted/">here</a>, and get the source code on <a href="https://github.com/AlexNisnevich/untrusted/">github</a>. At the time of the writing of this article, the project has received 1518 stars from the github community, and has been forked 197 times!</p>

<!-- More -->


<p>As I am speaking of fork, I want to introduce the initiative of my friend <a href="http://www.janosgyerik.com/">Janos Gyerik</a>, <a href="https://github.com/janosgyerik/hangoverx">HangoverX</a>, that will allow you to go on enjoying playing this meta-JavaScript adventure game with a complete re-written storyline.</p>

<h2>CodinGame, game solving challenges</h2>

<p><a href="http://www.codingame.com/cg/">CodinGame</a> is a platform where you can enjoy many different challenges: Kirk&rsquo;s Quest, Skynet Revolution, The Last Crusade&hellip; The only way to win? Code the best solution!</p>

<p>The platform set up challenges during a limited period of time, but I strongly suggest to try they practice multiplayer games, available at anytime, to play with their nice web interface and train your skills! For instance, you can play to Tron battle, and code the best algorithm to be the last one on the ring!</p>

<p><img src="http://pierre-jean.baraud.fr/images/gaming/tron-screenshot.png"></p>

<p>You will be able to choose your prefered language: Bash, C, C#, C++ Clojure, Dart, Go, Groovy, Haskell, Java, Javascript, ObjectiveC, Pascal, Perl, PHP, Python (2 &amp; 3), Ruby and Scala!</p>

<p>You can train your coded bot against the default AI, but the real interesting part is when you put it to the arena and fight against all other player algorithms, and/or choose some selected player to fight with!</p>

<p>Note that many challenges are sponsorized by game or software <a href="http://www.codingame.com/cg/#!contact">companies</a> that use these challenges to detect new talents! So, having fun and practicing your craft can actually benefit your career! what are you waiting for?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2014/05/07/docker/"/>
    <updated>2014-05-07T12:28:05+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2014/05/07/docker</id>
    <content type="html"><![CDATA[<p><img src="http://pierre-jean.baraud.fr/images/docker/docker-logo.png"></p>

<h2>What is Docker?</h2>

<p>It took me a while to really get what <a href="https://www.docker.io">Docker</a> is. Some people will present it as a light-view containers manager, and compare it to classic virtual machines. Others will present it as a way to deploy easily a software environment, and compare it to Chef.
It&rsquo;s actually both, and more.</p>

<!-- more -->


<p>Docker provides features for creating <em>agnostic</em> light-view containers, that can be can be shared, modified, and commit to repositories.
You can see it as a git version controller for app environments and a way to execute this environments.</p>

<p>Docker is based on technologies such as LXC, group control, and union file system.</p>

<h3>Docker is light-view</h3>

<p>Docker is light-view as it relies on the host kernel, and only cares about encapsulating the user-space environment that your process depends on. As a consequence, the overhead is minimal compare to a virtual machine, where an hypervisor has to communicate between the virtual machines and the host OS.</p>

<h3>Docker is safe</h3>

<p>Once you have built your image, you know for sure that you code will have exactly the same behaviour wherever you deploy it. Each container is completely independent of the host, as a virtual machine would be. Even if does not provide as much encapsulation as a VM (it runs on the same kernel), you can be confident about security if you configured it well.</p>

<h3>Docker is social</h3>

<p>Docker is based on a union file system, that you can see as layers. Each change is done on the top layer, that can be commit and shared with other. Thanks to the docker repository, you can base your own images on images shared by others.</p>

<h2>Why use Docker?</h2>

<p>I will try to explain a case scenario for a geek individual as me, and in a second part for a company.</p>

<h3>For a (geek) individual</h3>

<p>I have a few home servers and remote servers. As a geek, I try to install a lot of services on it (mail, project managers, blog frameworks, ans so on&hellip;). And as you can guess, all installations are not as smooth as a simple “apt-get install”.</p>

<p>Have you never spend hours to read several “How To” posts on internet to fix some broken installation? Modify the configurations, add dependency manually, re-compile, create databases to make your product work? And most of the time, many  of these services aren’t used after a while, and are just partially uninstalled&hellip;</p>

<p>Well, this situation induces several issues:</p>

<ul>
<li><p>It will be extremely to re-install the same services in other platform, as it involves a lot of manual steps</p></li>
<li><p>It will also be difficult to clean after removing your service, as you have done a lot of manual actions.</p></li>
<li><p>You may have security breaches. When you install a service to try it for a while, you don’t always focus on configuring it in a secure way. But as the app may be hosted on the same system as other services with potential sensitive information, you are at risk.</p></li>
</ul>


<p>The first two issues can be addressed with tools like Chef or Puppet, that automate environment setup through files called “recipes”. The third issue can be fixed by installing your service inside a dedicated virtual machine.</p>

<p>Using Chef or  Puppet will certainly help, but the result won’t be as certain as using Docker. Indeed, Chef/Puppet rely on the host system, and you can bump on some unexpected specificity. And you will have to solve them. Docker embed in a container all the user space filesystem, and as a consequence you have the <strong>guarantee </strong> that you will deploy on the same environment. On the other side, Chef or Puppet will be much more efficient in term of space as they don’t encapsulate anything: they use and share dependencies across the system.</p>

<p>Most of the time, though, people use Chef or Puppet on fresh VM, to address the third problem mentioned: encapsulation and security. And using a virtual machine implies a lot of overhead, maybe too much if the goal is just to have nice encapsulated environments.
The magic of Docker is that it uses light-view containers that rely on the host OS, and just bring what is needed for the service to run independently.
It will be really fast to launch, as you don’t have to boot a virtual OS, unlike a virtual machine.</p>

<p>A point of attention, though: in Docker, you should create a container per service, contrary to a virtual machine which may handle several parallel services (running processes).</p>

<h3>For  a company</h3>

<p>When you are a company, you may have specialised dedicated hardware (Solaris servers, embedded or exotic machines) to run your services, and your developers certainly code on more common machines such as laptop or desktop computers.</p>

<p>When the developers code some new features, they test them locally, they may have local unit tests, and maybe a dedicated machine to run integration tests. And then the code is deployed to the production machines.</p>

<p>This situation implies that the environment between the developer machine and the production machine may be really different, and some problems can occurred only in production, which make them difficult to prevent and/or fix.
If you use containers, you have the guarantee that your code will behave the same in your laptop and in your server, and you can setup your prod environment in a few seconds, just by running the corresponding containers.</p>

<p>And it goes the other way around too: once you created your containers on your laptop, you can send them directly to production to be deployed.</p>

<h2>Conclusion</h2>

<p>Docker is no magic bullet, but it is an elegant and pertinent solution for many use case. It was built upon standard Linux features like cgroups, LXC and AUFS.  Note that since version 0.9, the default container engine isn’t LXC but libcontainer, in order to make Docker more portable and be able to run on a wide range of host OS.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I Migrate to Jekyllrb]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2013/10/01/i-migrate-to-jekyllrb/"/>
    <updated>2013-10-01T11:55:56+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2013/10/01/i-migrate-to-jekyllrb</id>
    <content type="html"><![CDATA[<h2>From Wordpress to Jekyll</h2>

<p>I started a blog a few month ago with the framework wordpress, but I was not convinced about the user interface. For instance, here are a few drawbacks that annoyed me:</p>

<ul>
<li>The default templates are a little bit primitive, and you have to download and install new ones for custom layouts (recipies, etc.)</li>
<li>Creating a template is a heavy process, requiring some knowledge in PHP language: I don&rsquo;t know very much about PHP, and frankly, I&rsquo;m not really interested to learn it for the basic purpose of blogging. I would have prefer some more modern/sexy web technology if I have to dig into it (javascript frameworks, dart, python, ruby &hellip;).</li>
<li>No version-control by default</li>
</ul>


<p>Wordpress is still a really nice framework, but it didn&rsquo;t fit me needs. I started to look for newer blogging framework, and I discover Jekyll.</p>

<!-- more -->


<h2>Jekyll, the revelation</h2>

<p><a href="http://jekyllrb.com/">Jekyll</a> is a static blog-aware site generator. It is really simple to setup, and extremely flexible.
Here are the main reasons you should be interested in Jekyll:</p>

<ul>
<li>It uses great tools, already well-known by the developers community.</li>
<li>It is a static web site, so you can drop your site on any service that give you an accessible share from internet. It does <em>not request</em> any special language support (PHP, ruby, python&hellip;).</li>
<li>You can host it for free on the very cool service <a href="http://daringfireball.net/projects/markdown/syntax">github.io</a>, and even access it with your own domain name.</li>
</ul>


<p>I said Jekyll uses well know tools and language loved by developers. Here are they:</p>

<ul>
<li><strong><a href="http://daringfireball.net/projects/markdown/syntax">markdown</a></strong>: If you don&rsquo;t know Markdown yet, well, you should! Markdown is a text syntax that can be easily turned into html, but focus on readability in plain text format. It&rsquo;s really intuitive, elegant and efficient. You can find the details of the syntax <a href="http://daringfireball.net/projects/markdown/syntax">here</a>.</li>
<li><strong><a href="http://textile.sitemonks.com/">textile</a></strong>: If for a any reason you prefered textile, an alternative to markdown, it is also supported by default.</li>
<li><strong><a href="http://yaml.org/">YAML front-matter</a></strong>: Setting some YAML front-matter at the beginning of your article allow you to specify a lot of variables (the type, the title, the layout, &hellip;), that can be used to really tune the behaviour of your site.</li>
<li><strong><a href="http://www.ruby-lang.org/">Ruby</a></strong>: Even if I&rsquo;m not a ruby developper, I couldn&rsquo;t deny that it&rsquo;s a exciting language. It is also pretty easy to understand if you have to modify some plugins. Indeed, Jekyll can be extented with ruby scripts, that will add more features when you generate your site.</li>
<li><strong><a href="http://git-scm.com/">Git</a></strong>: Even if It&rsquo;s not mandatory, the framework is really design to integrate easily with the decentralized version control Git, which is one of the more used in recent collaborative project.</li>
</ul>


<h2>Ready to use: Jekyll Bootstrap, Octopress</h2>

<p>By default, jekyll comes with really simple theme, and not a lot of feature. Even if setting up new features (comments, themes, templates, &hellip;) is straightforward, I decided to save some time and clone the git repository of <a href="http://jekyllbootstrap.com/">Jekyll Bootstrap</a>, which include these features.</p>

<p>I bought on the site <a href="http://octopress.org/">wrapbootstrap.com</a> a CSS bootstrap template for blog, that I adapt for jekyll. I spent a little more time than expected to get the exact result I wanted, but it worth it!
I also had to fix a minor bug on the comments plugin provider.</p>

<p>I discovered a little bit too late the framework [Octopress][11], which seems exactly what I wanted, and that I would recommand to anyone starting a blog with jekyll.</p>

<h2>To do</h2>

<p>I still have unfinished tasks for the blog:</p>

<ul>
<li><p>As I create my own theme for Jekyll, there is some depencies between the theme and my layout, which shouldn&rsquo;t exist if I would have create a clean generic template to be deployed for any blog. I don&rsquo;t know if Octopress is more obvious in its architecture, but I found on Jekyll Bootstrap that it can sometimes be tricky to choose what should be in the theme and what should be in the blog layout.</p></li>
<li><p>I used some private plugin on Jekyll (to generate a tag cloud for instance), which isn&rsquo;t supported on github. I still host my code on github, but I have to publish the generated site and the source code on different git branches to have the blog accessible on [<a href="http://pierre-jean.github.io">http://pierre-jean.github.io</a>]. Actually, I host it on my own server, but it could be usefull to really host it on github.</p></li>
<li><p>Publishing the blog require manual step (SSH connection to my server, and run the command to pull/push from git and generate the static content): all of these could be automated.</p></li>
</ul>


<p> As a conclusion, I&rsquo;m very happy to be able to finally write my post on markdown, and simply commit them with git. If you are a developper, you really should enjoy jekyll! If you have any advices/tweak/opinions, feel free to share them with a comment!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction to AngularJS]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2013/08/17/introduction-to-angularjs/"/>
    <updated>2013-08-17T11:13:23+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2013/08/17/introduction-to-angularjs</id>
    <content type="html"><![CDATA[<p><img src="http://pierre-jean.baraud.fr/images/angularjs/AngularJS.jpg"></p>

<p>I discovered recently this exciting framework, and even if I&rsquo;m still a beginner in it, I presented it to my colleagues to share my enthusiasm.
Here are the slides i used for the presentation.</p>

<!-- more -->




<script async="true" class="speakerdeck-embed" data-id="7a7a33c0bb5301309b3a023921bdbc68" src="//speakerdeck.com/assets/embed.js"> </script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Be Passionate]]></title>
    <link href="http://pierre-jean.baraud.fr/blog/2013/08/10/be-passionate/"/>
    <updated>2013-08-10T15:46:47+01:00</updated>
    <id>http://pierre-jean.baraud.fr/blog/2013/08/10/be-passionate</id>
    <content type="html"><![CDATA[<h2>Live your passion&hellip;now</h2>

<p>I am a cautious person. I like to weigh pros and cons before making a choice. I always prevailed adaptability over personal beliefs. But if I learned one thing in the last few years, it&rsquo;s that being <strong>good is all about passion</strong>.</p>

<p>There are plenty of average software developers considering development as a job. There is nothing wrong about that. But if you really want to learn and progress, you should focus on people who live their passion.</p>

<!-- more -->


<p>Don&rsquo;t be afraid to take the risk of following your dream. If you really do what you believe in, you will be 200% more efficient! I know this might sound naive, but it&rsquo;s not: you only have one life, don&rsquo;t realize too late it&rsquo;s not the one you want.</p>

<h2>You have the potential to improve</h2>

<p>Courage is about trusting yourself. Don&rsquo;t hide your weakness. <strong>Share</strong> what you know. Focus on what you have to learn: there is a world of knowledge waiting for you, and you should be excited about it!</p>

<p>I&rsquo;m a truly bad example on this, but it&rsquo;s never too late to change: open-source projects are a very cool way to become better. It&rsquo;s about taking initiatives, accepting unpleasant remarks, learning and improving!</p>

<h2>Read, read, read and participate!</h2>

<p>There is a looong list of fascinating people out there who inspire me every day. But for this post, I will focus on one: Jeff Atwood, the guy who created the Stack Exchange framework (and the well-known website that use it: <a href="http://stackoverflow.com">stackoverflow.com</a>). <a href="http://www.codinghorror.com/blog/" title="Coding Horror Blog">His blog</a> and <a href="http://www.codinghorror.com/blog/2012/07/coding-horror-the-book.html" title="Books section of coding horror">his books</a> really impacted me on how to become better on what I do. (for French speakers, some articles from <a href="http://vincent.jousse.org/" title="Blog de Vincent Jousse">this blog</a> will have the same spirit of motivation).</p>

<p>Encouraged by some friends, I decided to start a blog, because it&rsquo;s a good exercise for a developer: writing instead of reading, producing instead of consuming. It forces involvement in your passion, and I really hope to learn about this experience.</p>

<h2>If you don&rsquo;t believe me&hellip;believe him!</h2>

<p>On a lighter note, I let Schwarzenegger sum up my speech:</p>

<div class="embed-video-container"><iframe src="http://www.youtube.com/embed/vH0nP4NzS9M "></iframe></div>



]]></content>
  </entry>
  
</feed>
