<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Yabage]]></title>
  <link href="http://pierre-jean.github.io/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://pierre-jean.github.io/"/>
  <updated>2014-06-02T19:06:03+02:00</updated>
  <id>http://pierre-jean.github.io/</id>
  <author>
    <name><![CDATA[Pierre-Jean Baraud]]></name>
    <email><![CDATA[pierre-jean@baraud.fr]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hosting Docker Containers]]></title>
    <link href="http://pierre-jean.github.io/blog/2014/06/02/host-docker-containers/"/>
    <updated>2014-06-02T10:52:40+02:00</updated>
    <id>http://pierre-jean.github.io/blog/2014/06/02/host-docker-containers</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/docker/host-solutions.png"></p>

<p>I already wrote about Docker, and today I will present different solutions to host your lovely docker containers. If you  want to know more about Docker, you can read <a href="http://pierre-jean.baraud.fr/blog/categories/docker/">my previous post on this subject</a>.</p>

<!-- More -->


<h2>Dedicated servers</h2>

<p>If you already have a dedicated server (hosted in a data center or just a home server), you can just install docker on it, and setup a proxy (nginx, apache, etc.) to redirect the requests to the right local port according to the domain.</p>

<p>You can do this in a static way or use the <a href="http://docs.docker.io/use/ambassador_pattern_linking/">ambassador pattern as presented here</a>. The static method is the simplest if you only manage a few containers, but if you want a robust environment to deploy a large amount of containers, you should have a look on how to deploy ambassador containers.</p>

<p>Instructions for installing Docker on several distributions are available in the <a href="http://docs.docker.io/installation/">official documentation</a>. For instance, on Ubuntu 14.04, you can install it directly from the package manager:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo apt-get update
</span><span class='line'>$ sudo apt-get install docker.io
</span><span class='line'>$ sudo ln -sf /usr/bin/docker.io /usr/local/bin/docker</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Then, you can build and run your containers, as explained in my previous posts. If you don&rsquo;t have any firewall blocking the port, your containers should already be accessible from the net.</p>

<p><img class="center" src="/images/docker/docker-host-direct.png"></p>

<p>Nevertheless, you may want to access your containers and their service by the default port. You can do this with a simple HTTP reverse proxy, or if you have only one container running for a specified service, you can map them directly to the host default port for this service.
The command:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo  docker run -p 22:22 ssh-image /usr/sbin/sshd -D</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>will launch the container based on image <em>ssh-image</em> and will map the port 22 of the container to the port 22 of the host.</p>

<p><img class="center" src="/images/docker/docker-host-proxy.png"></p>

<p>I won&rsquo;t enter into technical details in this post, but you can find a lot of resources on the net about how to setup a reverse proxy..</p>

<p>This solution is maybe the first one you will try, at least for experiencing with docker.</p>

<p><strong> Pros and cons:</strong></p>

<ul>
<li><p><em>Difficulty:</em> Even if installing Docker isn&rsquo;t difficult, maintaining a dedicated server could really end up in many headaches. You will have to manage upgrades, security issues, problems and configurations by yourself. Don&rsquo;t underestimate this part, especially if it&rsquo;s not your specialty.</p></li>
<li><p><em>Scalability:</em> You&rsquo;re on your own. If you already thinked this through and designed a nice solution to scale your services, it can work pretty good. Or fail terribly.</p></li>
<li><p><em>Price:</em> If you use your server 100% of its capacity, this may be the cheapest solution. Dedicated server are quite expensive, but you will also have a large amount of power to manage several services on the same machines.</p></li>
</ul>


<h2>Virtual Machines and VPS</h2>

<p>This is exactly the same principle than before, except that you are running on a virtual machine. If you don&rsquo;t need the power of a dedicated machine, this solution gives you (more or less) the same freedom as the previous one but for a really cheaper price. This is also true with any IAAS solution (<em>Infrastructure as a Service</em>, for instance: Amazon EC2, Google Compute Engine, etc.). If you use a PAAS (Platform as a service) solution, you have to check if you can run docker containers on it, which, for the moment, is unlikely.</p>

<p><strong>Pros and cons:</strong></p>

<ul>
<li><em>Difficulty:</em> The same as the dedicated server; you will have to setup the platform by yourself.</li>
<li><em>Scalability:</em> You may be able to find it a little bit easier to scale with VM, but you will have to think your scalabitlity solution by yourself, just like with dedicated.</li>
<li><em>Price:</em> Cheaper than a dedicated server, as you only use the power you need. You may even find IAAS solution that let you pay according to the cpu power used or the time your server is up (per minutes).</li>
</ul>


<h2>DigitalOcean</h2>

<p><a href="https://www.digitalocean.com">DigitalOcean</a> is a hosting company, that offers virtual machines with preinstalled environments designed for developers.</p>

<p>You can setup really easily what they call a <em>droplet</em>, which is a KVM instance running on SSD hard drive with more or less CPU and storage depending on the pricing solution.</p>

<p>What is cool is that they offer to setup machines with docker already installed. The design of the website is clear and nice, and the pricing policy flexible.</p>

<p>Let&rsquo;s see how to create a droplet with Docker installed.</p>

<p>First of all <strong><a href="https://cloud.digitalocean.com/registrations/new">Sign up</a></strong>. They will ask you your credit card information, so that you can create droplet as soon as the process is finished.</p>

<p>Then <strong><a href="https://cloud.digitalocean.com/login">log in</a></strong>, and clic on <strong>Create Droplet</strong>.</p>

<p><img class="center" src="/images/docker/digitalocean-screen01.png"></p>

<p>You give a name to the droplet (the name doesn&rsquo;t really matter, it&rsquo;s just for you):</p>

<p><img class="center" src="/images/docker/digitalocean-screen02.png"></p>

<p>And select the type of droplet you need. As you can see, prices start at 5$/month or 0.007$/hour for a basic configuration (1 CPU/512GB RAM/20GB SSD) to 640$/month or 0.952$/hour for the most powerfull configuration (20 CPU/64GB RAM/640GB SSD). Let&rsquo;s select the basic configuration: you can delete it whenever you want after this test, and it will just cost a few cents.</p>

<p><img class="center" src="/images/docker/digitalocean-screen03.png"></p>

<p>You select the region of your droplet. For the moment are available: New York, San Francisco, Amsterdam and Singapore.</p>

<p><img class="center" src="/images/docker/digitalocean-screen04.png"></p>

<p>You can install an OS distribution but also an image with applications already installed. Let&rsquo;s click on Applications and select Docker. They provide the latest Docker release available, which is nice.</p>

<p><img class="center" src="/images/docker/digitalocean-screen05.png"></p>

<p>Finally, you can choose to add a previously saved SSH Key, if you have one.</p>

<p>Once everything is selected, click <strong>Create Droplet</strong>.</p>

<p><img class="center" src="/images/docker/digitalocean-screen06.png"></p>

<p><img class="center" src="/images/docker/digitalocean-screen07.png"></p>

<p>The Droplet is set up in less than a minute. The root password will be emailed to you if you don&rsquo;t have associate any SSH Key with the droplet.
The IP of the machine is displayed just after its creation.</p>

<p><img class="center" src="/images/docker/digitalocean-screen08.png"></p>

<p>You can ssh into the machine and launch directly your docker containers!</p>

<p>DigitalOcean provide a nice and clear interface, you can interact with it through <a href="https://developers.digitalocean.com/">their REST API</a>, the prices are cheap and flexible.</p>

<h2>Tutum</h2>

<p>If you are really looking for a platform dedicated to Docker, there is <a href="http://www.tutum.co/">Tutum</a>.
Tutum is a &ldquo;Container-as-a-service&rdquo;, and is the simplest solution to run docker containers that I&rsquo;ve seen.</p>

<p>Let&rsquo;s see how to setup and run a container in Tutum.</p>

<p>First of all, <strong><a href="https://app.tutum.co/accounts/register/">sign up</a></strong>, you will notice that no credit card information will be asked. Indeed, you can create your first container for free for a month, which is a great way to test the platform. You&rsquo;ll see some warnings alerting that Tutum is still in beta, but Docker is also still in beta, so it shouldn&rsquo;t be an issue, as you shouldn&rsquo;t use Docker in production for the moment.</p>

<p>Once you are <a href="https://app.tutum.co/">logged in</a>, click on <strong>Launch your first application</strong>.</p>

<p><img class="center" src="/images/docker/tutum-screen01.png"></p>

<p>You can choose one of the preset docker images to start with&hellip;</p>

<p><img class="center" src="/images/docker/tutum-screen02.png"></p>

<p>or choose from the official docker index or any other registry.</p>

<p><img class="center" src="/images/docker/tutum-screen03.png"></p>

<p>And if you want to keep your images private, Tutum provide a <a href="http://docs.tutum.co/features/registry/">private registry</a> where you can push your docker images!</p>

<p>Let&rsquo;s try the wordpress default image!</p>

<p><img class="center" src="/images/docker/tutum-screen04.png"></p>

<p>Once selected, you can choose a name for your container, the tag (version) of the image, and the resources allocated to the container. It goes from $4/month (0.25 CPU ECU/256MB) to $64/month (4 CPU ECU/4GB Memory). Let&rsquo;s try the XS Solution (free for a month).
Click on <strong>Launch</strong>.</p>

<p><img class="center" src="/images/docker/tutum-screen05.png"></p>

<p>In just a few seconds, the container is setup and ready to use.</p>

<p><img class="center" src="/images/docker/tutum-screen06.png"></p>

<p>When you click on your container, you find directly the exposed port, and a link to the application.</p>

<p><img src="/images/docker/tutum-screen07.png"></p>

<p>If you click on it, <em>tadaaam</em>, your site is ready and waiting for you.</p>

<p><img class="center" src="/images/docker/tutum-screen08.png"></p>

<p>With Tutum, you manage directly your docker containers, without worrying about any infrastructure issue. It provides dedicated screen for Logs, Environment variables and monitoring. It also provides a <a href="http://docs.tutum.co/reference/api/">REST API</a> to interact with your containers. And if you want to use a custom domain, You can also setup it when you create your container.</p>

<p>The interface is neat and clear, and you can scale your services really easily. The prices are fair regarding the services they provide (scaling, load balancing, web proxies). It is really enjoyable to deploy so easily any docker images in the cloud in a few seconds.</p>

<p>And you, how do you deploy your docker containers?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Deeper Look Into Dockerfiles]]></title>
    <link href="http://pierre-jean.github.io/blog/2014/05/19/deeper-look-dockerfile/"/>
    <updated>2014-05-19T17:18:54+02:00</updated>
    <id>http://pierre-jean.github.io/blog/2014/05/19/deeper-look-dockerfile</id>
    <content type="html"><![CDATA[<p>I introduced in <a href="http://pierre-jean.baraud.fr/blog/2014/05/14/fist-look-dockerfile/">a previous post</a> how to create <a href="https://www.docker.io/">Docker</a> images interactively and with a <em>Dockerfile</em>.</p>

<p>In this post, I will focus on good practices and see how a proper repository is realized. Indeed, in my previous post, my example was a little bit trivial, and if you want to create your own images through a Dockerfile, you will surely bump into difficulties: how do I manage interactive installation that ask a user input during install? How should I configure my application after installation? And many others&hellip;</p>

<!-- More -->


<h2>Trusted Builds: a good way to learn</h2>

<p>When you commit your image in a local repository, or push it into a remote repository, you only push the built image, as a file.
Trusted build is a mechanism to build automatically an image from its sources: the docker index will built the image each time a commit is done on the public github repository corresponding to the docker image.
This is a great way to study popular images and see how their maintainers manage difficulties you can have with the settings of some images.</p>

<p>You can browse and search into the official Docker index of repositories from the <a href="https://index.docker.io/">website</a>, or interact with it in command line with <code>docker search</code>, <code>docker pull</code> and <code>docker push</code>.
Let&rsquo;s have a look to the <em>mysql</em> image of the repository <em>tutum</em> (provided by <a href="http://tutum.co">tutum.co</a>), available <a href="https://index.docker.io/u/tutum/mysql/">here</a>. As it is a trusted build, you have access to the <a href="https://github.com/tutumcloud/tutum-docker-mysql">github page</a> from where the image is built.</p>

<p><strong>Erratum: the repository has changed since the date of this post, I let the information available here, but you may find differences with the sources hosted on Github.</strong></p>

<h2>Dockerfile</h2>

<p>Let&rsquo;s have a look the docker file, and the good practices it includes.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM ubuntu:trusty
</span><span class='line'>MAINTAINER Fernando Mayo &lt;a href="&#x6d;&#97;&#105;&#x6c;&#x74;&#x6f;&#x3a;&#x66;&#101;&#114;&#110;&#97;&#110;&#x64;&#111;&#64;&#x74;&#x75;&#116;&#x75;&#x6d;&#46;&#x63;&#111;">&#x66;&#101;&#114;&#x6e;&#x61;&#x6e;&#x64;&#111;&#64;&#x74;&#x75;&#x74;&#117;&#x6d;&#46;&#x63;&#x6f;&lt;/a>&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;h1>Install packages&lt;/h1>
</span><span class='line'>
</span><span class='line'>&lt;p>RUN apt-get update
</span><span class='line'>RUN DEBIAN_FRONTEND=noninteractive apt-get -y install supervisor mysql-server pwgen&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;h1>Add image configuration and scripts&lt;/h1>
</span><span class='line'>
</span><span class='line'>&lt;p>ADD start.sh /start.sh
</span><span class='line'>ADD run.sh /run.sh
</span><span class='line'>ADD supervisord-mysqld.conf /etc/supervisor/conf.d/supervisord-mysqld.conf
</span><span class='line'>ADD my.cnf /etc/mysql/conf.d/my.cnf
</span><span class='line'>ADD mysqld_charset.cnf /etc/mysql/conf.d/mysqld_charset.cnf
</span><span class='line'>ADD create_mysql_admin_user.sh /create_mysql_admin_user.sh
</span><span class='line'>ADD import_sql.sh /import_sql.sh
</span><span class='line'>RUN chmod 755 /*.sh&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>EXPOSE 3306
</span><span class='line'>CMD [&ldquo;/run.sh&rdquo;]</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h3>FROM command</h3>

<p>The FROM command defines the base image for this image.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM ubuntu:trusty</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>You can see that the maintainer used a tag to define precisely which version of Ubuntu to use. <strong>You should always define a tagged version of your base image</strong> to precisely define which release of the distribution your image relies on.</p>

<h3>MAINTAINER</h3>

<p>The maintainer is vital tag, to define the author of the image and a way to contact it.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MAINTAINER Fernando Mayo &lt;a href="&#109;&#x61;&#x69;&#x6c;&#x74;&#x6f;&#58;&#102;&#x65;&#x72;&#110;&#x61;&#110;&#100;&#x6f;&#x40;&#116;&#117;&#116;&#x75;&#x6d;&#46;&#x63;&#111;">&#102;&#101;&#x72;&#x6e;&#97;&#110;&#100;&#111;&#x40;&#x74;&#x75;&#x74;&#117;&#x6d;&#x2e;&#x63;&#x6f;&lt;/a></span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h3>COMMENTS</h3>

<p>You can add comments with the character <code>#</code>. You should always add comments to explain the goal of each block of instructions.</p>

<h3>RUN command</h3>

<p>After each <code>RUN</code> instruction, the image is committed, and the following RUN instruction is executed on the newly committed image.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;h1>Install packages&lt;/h1>
</span><span class='line'>
</span><span class='line'>&lt;p>RUN apt-get update
</span><span class='line'>RUN DEBIAN_FRONTEND=noninteractive apt-get -y install supervisor mysql-server pwgen</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>We can notice several practices here:</p>

<ul>
<li><p>No usage of <code>apt-get upgrade</code>: Indeed, you just want to add on this layer what is needed for the container. If you want to upgrade the system, you should <strong>upgrade the base image</strong>, as it is its role to offer the system environment.</p></li>
<li><p>Avoid interaction: the <code>RUN</code> command is <strong>executed in a non-interactive way</strong>. As a consequence, you don&rsquo;t want to been ask for confirmation when installing package: you must use the <code>-y</code> option in <code>apt-get install -y &lt;packages&gt;</code>. Moreover some packages ask questions during installation about account creation, default configuration, etc. It is the case for mysql-server for instance. That&rsquo;s why the author put the variable <code>DEBIAN_FRONTEND</code> to <code>noninteractive</code>, in order to inform that there won&rsquo;t be any interaction during installation.</p></li>
<li><p>Finally, there is the <code>apt-get update</code>. It is the most litigious command. If you install your packages via <code>apt-get</code>, you have no choice but to update the index of packages before the install: you don&rsquo;t want to have an outdated cache and broken links during installation. Nevertheless, it also means that the Dockerfile can create slightly different images depending of the date of build. Indeed, the version of a package or a dependency of a package you want to install can have change in the repository. The only work around is to install your packages via a direct link to a binary package or from source. Anyway, the consequence can be neglected as you don&rsquo;t want to rebuild your image every day, and you should build it once and use it / share it as long as you want to use the same environment.</p></li>
</ul>


<h3>ADD command</h3>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;h1>Add image configuration and scripts&lt;/h1>
</span><span class='line'>
</span><span class='line'>&lt;p>ADD start.sh /start.sh
</span><span class='line'>ADD run.sh /run.sh
</span><span class='line'>ADD supervisord-mysqld.conf /etc/supervisor/conf.d/supervisord-mysqld.conf
</span><span class='line'>ADD my.cnf /etc/mysql/conf.d/my.cnf
</span><span class='line'>ADD mysqld_charset.cnf /etc/mysql/conf.d/mysqld_charset.cnf
</span><span class='line'>ADD create_mysql_admin_user.sh /create_mysql_admin_user.sh
</span><span class='line'>ADD import_sql.sh /import_sql.sh</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>The maintainer has added two types of external files here:</p>

<ul>
<li><p><strong>Configuration files</strong>: you want your image to be operational immediately after the build. You have to provide working default configurations that allow to use the package in rational conditions. You must of course allow the user to override the configuration settings (by adding its own configuration files, or with environment variables).</p></li>
<li><p><strong>Scripts files</strong>: As you want to automate all setup steps, it is a good idea to wrap your launcher inside scripts that could executes some  checking and actions for you (<em>Database creation</em>, <em>Account creation</em>, etc.).</p></li>
</ul>


<h3>EXPOSE command</h3>

<p>The Dockerfile defines the ports you want to expose to the host system to access the service you will run on the container, with the instruction <code>EXPOSE</code>.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>EXPOSE 3306</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Even if you can tell on which host port you want to map the local port, this is good practice to let Docker framework dynamically map the port to the host. Indeed, if you map yourself the port, you won&rsquo;t be able to launch several containers from the same Dockerfile, as the first one will lock the port for itself.</p>

<h3>CMD command</h3>

<p>Finally, you can tell Docker which process it should execute by default when launching a container.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CMD [&ldquo;/run.sh&rdquo;]</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Here, as the maintainer wrapped the process into a script to automate account creation, it launches the script instead of the process.</p>

<h2>Supervisor</h2>

<p>If you study the scripts, you may have noticed that the maintainer doesn&rsquo;t launch the mysql server directly, but launch instead a process called <strong>Supervisord</strong>. <a href="http://supervisord.org/">Supervisor</a> is a process control system, a little bit like <code>init</code>, that allow you to manage the execution of several processes.</p>

<p>Indeed, I told you in my previous article that a Docker container can only run one job: there isn&rsquo;t any <code>init</code> running instance to manage the lifecycle of several process executions in a Docker container. Nevertheless, you will certainly want to be able to manage several processes or job in a same container: for example, running a SSH server and at the same time another kind of server. You can use Supervisor to do that.</p>

<p>Better, as explained in this <a href="http://blog.trifork.com/2014/03/11/using-supervisor-with-docker-to-manage-processes-supporting-image-inheritance/">article</a>, you can use inheritance to include the Supervisor configuration files from you base image, to launch the services the base image already provide in parallel with the jobs you define in your own configuration.</p>

<h2>README.md</h2>

<p>Finally, the author of the image included a README.md explaining how to build, launch and configure the container. It is really handy and you always should include it if you create your own trusted build. The README is displayed on the<a href="https://index.docker.io/u/tutum/mysql/"> Docker index website</a> when you look for the image.</p>

<h2>What&rsquo;s next?</h2>

<p>You have seen how is built a popular docker image. If you want to create your own Docker image, you should search for similar images in the Docker index and analyze their Dockerfiles. All trusted build are available through their github page, so it&rsquo;s a really easy task.</p>

<p>I hope this post will help you to create great images for yourself and the community!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A First Look Into Dockerfiles]]></title>
    <link href="http://pierre-jean.github.io/blog/2014/05/14/fist-look-dockerfile/"/>
    <updated>2014-05-14T14:45:54+02:00</updated>
    <id>http://pierre-jean.github.io/blog/2014/05/14/fist-look-dockerfile</id>
    <content type="html"><![CDATA[<p>A <a href="http://pierre-jean.baraud.fr/blog/2014/05/07/docker/">week ago</a>, I introduced the framework <a href="http://docker.io">Docker</a>. Docker is a lightview virtualized environment. It allows to build, manage and run containers to easily deploy an app in an iso environment.
I will introduce today how to create containers interactively and through Dockerfile.</p>

<!-- More -->


<h2>Hands on containers and images</h2>

<p>If you&rsquo;re not familiar with Docker, I strongly recommend you to have a look to their <a href="https://www.docker.io/gettingstarted/#">interactive tutorial</a>. It is well done, efficient, and get you into the swing of things. The <a href="https://www.docker.io/learn/dockerfile/">Dockerfile tutorial</a> will also give you all the basis. I will try here to sum up the more important concepts.</p>

<h3>What is a container?</h3>

<p>A container can be represented by two main components:</p>

<ul>
<li>A running job</li>
<li>A filesystem modified by the job</li>
</ul>


<p>The filesystem itself is a multilayered union filesystem, with the top layer saving the current modifications, and the underlying layers read only images. Let&rsquo;s have a deeper look on what is a multilayered union filesystem.</p>

<h3>Images and AUFS</h3>

<p>Let&rsquo;s build our own customized image! First of all, let&rsquo;s pull an image from the docker index.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker pull ubuntu:precise</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>This will download an image with the files of Ubuntu Precise distribution (without the Kernel, as it uses the host kernel).</p>

<p><img class="center" src="/images/docker/docker-image-creation-00.png"></p>

<p>You can have information about downloaded images with the command <code>docker images</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="gp">$</span> sudo docker images
</span><span class='line'><span class="go">REPOSITORY           TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span>
</span><span class='line'><span class="go">ubuntu               precise             74fe38d11401        3 weeks ago         209.6 MB</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>We will then interact with it by launching a job from this filesystem.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker run ubuntu:precise apt-get install -y memcached</span>
</span><span class='line'><span class="go">[&amp;hellip;]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>When executing this command, we create a container. This container will create a writable layer for its filesystem, and base it upon the image <em>ubuntu:precise</em>. It will then launch the process <code>apt-get</code> with the argument <code>install -y memcached</code></p>

<p><img class="center" src="/images/docker/docker-image-creation-01.png"></p>

<p>I didn&rsquo;t affect any name to the container in the previous command. To find the id of a running container, you can type the command <code>docker ps</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker ps</span>
</span><span class='line'><span class="go">CONTAINER ID        IMAGE               COMMAND                CREATED              STATUS              PORTS               NAMES</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Here, I don&rsquo;t have any running container. Indeed, the status of the container is related to the status of its running job. As a consequence, once <code>apt-get install -y memcached</code> returned, the container is stopped.</p>

<p>To display all containers currently on your machine, you can type <code>docker ps -a</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker ps -a</span>
</span><span class='line'><span class="go">CONTAINER ID        IMAGE               COMMAND                CREATED              STATUS              PORTS               NAMES</span>
</span><span class='line'><span class="go">cab24787db86        ubuntu:12.04        apt-get install -y m   About a minute ago   Exit 0                                  clever_curie&lt;br/&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>I can now commit the content of the filesystem of this container into a new image:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker commit cab24</span>
</span><span class='line'><span class="go">9f97edd4e9ee794eca4c40db3122b5c635f0e2f92c3b0e62deaac9e28af1a868</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>You will note that typing just the first digits of the id is enough to find it, as in git.</p>

<p>You image is now visible when you display your docker images:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker images</span>
</span><span class='line'><span class="go">REPOSITORY           TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span>
</span><span class='line'><span class="go">&lt;none&gt;               &lt;none&gt;              9f97edd4e9ee        3 minutes ago       246.2 MB</span>
</span><span class='line'><span class="go">ubuntu               precise             74fe38d11401        3 weeks ago         209.6 MB</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>You can run a new container based on this new image:
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker run &amp;mdash;name &amp;ldquo;bash-on-mysql-image&amp;rdquo; -i -t 9f97ed /bin/bash</span>
</span><span class='line'><span class="gp">root@1ddbe7cefb87:/#</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>You will now run a new container, with the process <code>/bin/bash</code>, <code>-i</code> and <code>-t</code> options for respectively running it interactively and attaching a pseudo  tty, <code>--name</code> to name our container, that will put a writable layer upon our image 9f97edd, which is itself based on our images ubuntu:precise.</p>

<p><img class="center" src="/images/docker/docker-image-creation-03.png"></p>

<p>You may have understand now that referencing the images by their id won&rsquo;t be handy, That&rsquo;s why you will prefer to organize your images under</p>

<p>If you want to organize your images, it is better to commit them under your local repository.
You could have run this command to commit from the container:
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker commit 9f97e yabage/ubuntu-memcached</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Or you can tag the current image directly
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">~$ sudo docker tag 9f97e yabage/ubuntu-memcached</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>The Dockerfile</h2>

<p>You have seen how to build an image by interacting directly with the container. Nevertheless, most of the time you will want to share your images through &ldquo;recipes&rdquo; allowing others to <strong>build</strong> themselves your images.
This is what <strong>Dockerfiles</strong> are for.</p>

<p>The Dockerfile lists the instruction on how to build your image and what to run on the container.</p>

<p>As you want to obtain the same image in every circumstances, you will have to <strong>avoid</strong> any operation that <strong>doesn&rsquo;t result in a controlled and guaranted state</strong>. For instance, you should not do any <code>apt-get upgrade</code> in a Dockerfile, as you don&rsquo;t controlled the result : indeed, depending the date your launching it, the upgrade could be different. Moreover, for technical reasons, there is a high chance that the upgrade fails. If you want to upgrade your distribution, you should update the base image your Dockerfile rely on.</p>

<p>Now let&rsquo;s see how to build the first container in a Dockerfile:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>FROM ubuntu:precise #the base image of this build script&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>RUN apt-get install -y memcached&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p></span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Well&hellip;that&rsquo;s all. You know have a container with memcached installed.</p>

<p>I kept this Dockerfile minimalistic on purpose, but you will want to define the maintainer of the Dockerfile with the tag <code>MAINTAINER</code>, define the default process to launch with <code>CMD</code> and a lot of other useful instructions.
For now I will stick to this version.</p>

<p>I would like to focus your attention on a point: each RUN instruction will commit the current layer and create a new one upon it. <strong>The state of the memory is forgotten</strong> between two <code>RUN</code> instructions. Only the filesystem is kept.</p>

<p>To build an image, you put these instructions in a file called <em>Dockerfile</em>, then execute the <code>build</code> command from the same folder:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">sudo docker build .</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>It will build the container and return its id. If you want to name the container when building, you can do it with the <code>-t</code> option</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">sudo docker build -t ubuntu-memcached .</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>You have seen a very quick introduction to Dockerfile. I will soon write an article about how to write a proper Docker image, following good practices, so that you can share them with your friends and the community!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker]]></title>
    <link href="http://pierre-jean.github.io/blog/2014/05/07/docker/"/>
    <updated>2014-05-07T13:28:05+02:00</updated>
    <id>http://pierre-jean.github.io/blog/2014/05/07/docker</id>
    <content type="html"><![CDATA[<p><img src="/images/docker/docker-logo.png"></p>

<h2>What is Docker?</h2>

<p>It took me a while to really get what <a href="https://www.docker.io">Docker</a> is. Some people will present it as a light-view containers manager, and compare it to classic virtual machines. Others will present it as a way to deploy easily a software environment, and compare it to Chef.
It&rsquo;s actually both, and more.</p>

<!-- more -->


<p>Docker provides features for creating <em>agnostic</em> light-view containers, that can be can be shared, modified, and commit to repositories.
You can see it as a git version controller for app environments and a way to execute this environments.</p>

<p>Docker is based on technologies such as LXC, group control, and union file system.</p>

<h3>Docker is light-view</h3>

<p>Docker is light-view as it relies on the host kernel, and only cares about encapsulating the user-space environment that your process depends on. As a consequence, the overhead is minimal compare to a virtual machine, where an hypervisor has to communicate between the virtual machines and the host OS.</p>

<h3>Docker is safe</h3>

<p>Once you have built your image, you know for sure that you code will have exactly the same behaviour wherever you deploy it. Each container is completely independent of the host, as a virtual machine would be. Even if does not provide as much encapsulation as a VM (it runs on the same kernel), you can be confident about security if you configured it well.</p>

<h3>Docker is social</h3>

<p>Docker is based on a union file system, that you can see as layers. Each change is done on the top layer, that can be commit and shared with other. Thanks to the docker repository, you can base your own images on images shared by others.</p>

<h2>Why use Docker?</h2>

<p>I will try to explain a case scenario for a geek individual as me, and in a second part for a company.</p>

<h3>For a (geek) individual</h3>

<p>I have a few home servers and remote servers. As a geek, I try to install a lot of services on it (mail, project managers, blog frameworks, ans so on&hellip;). And as you can guess, all installations are not as smooth as a simple “apt-get install”.</p>

<p>Have you never spend hours to read several “How To” posts on internet to fix some broken installation? Modify the configurations, add dependency manually, re-compile, create databases to make your product work? And most of the time, many  of these services aren’t used after a while, and are just partially uninstalled&hellip;</p>

<p>Well, this situation induces several issues:</p>

<ul>
<li><p>It will be extremely to re-install the same services in other platform, as it involves a lot of manual steps</p></li>
<li><p>It will also be difficult to clean after removing your service, as you have done a lot of manual actions.</p></li>
<li><p>You may have security breaches. When you install a service to try it for a while, you don’t always focus on configuring it in a secure way. But as the app may be hosted on the same system as other services with potential sensitive information, you are at risk.</p></li>
</ul>


<p>The first two issues can be addressed with tools like Chef or Puppet, that automate environment setup through files called “recipes”. The third issue can be fixed by installing your service inside a dedicated virtual machine.</p>

<p>Using Chef or  Puppet will certainly help, but the result won’t be as certain as using Docker. Indeed, Chef/Puppet rely on the host system, and you can bump on some unexpected specificity. And you will have to solve them. Docker embed in a container all the user space filesystem, and as a consequence you have the <strong>guarantee </strong> that you will deploy on the same environment. On the other side, Chef or Puppet will be much more efficient in term of space as they don’t encapsulate anything: they use and share dependencies across the system.</p>

<p>Most of the time, though, people use Chef or Puppet on fresh VM, to address the third problem mentioned: encapsulation and security. And using a virtual machine implies a lot of overhead, maybe too much if the goal is just to have nice encapsulated environments.
The magic of Docker is that it uses light-view containers that rely on the host OS, and just bring what is needed for the service to run independently.
It will be really fast to launch, as you don’t have to boot a virtual OS, unlike a virtual machine.</p>

<p>A point of attention, though: in Docker, you should create a container per service, contrary to a virtual machine which may handle several parallel services (running processes).</p>

<h3>For  a company</h3>

<p>When you are a company, you may have specialised dedicated hardware (Solaris servers, embedded or exotic machines) to run your services, and your developers certainly code on more common machines such as laptop or desktop computers.</p>

<p>When the developers code some new features, they test them locally, they may have local unit tests, and maybe a dedicated machine to run integration tests. And then the code is deployed to the production machines.</p>

<p>This situation implies that the environment between the developer machine and the production machine may be really different, and some problems can occurred only in production, which make them difficult to prevent and/or fix.
If you use containers, you have the guarantee that your code will behave the same in your laptop and in your server, and you can setup your prod environment in a few seconds, just by running the corresponding containers.</p>

<p>And it goes the other way around too: once you created your containers on your laptop, you can send them directly to production to be deployed.</p>

<h2>Conclusion</h2>

<p>Docker is no magic bullet, but it is an elegant and pertinent solution for many use case. It was built upon standard Linux features like cgroups, LXC and AUFS.  Note that since version 0.9, the default container engine isn’t LXC but libcontainer, in order to make Docker more portable and be able to run on a wide range of host OS.</p>
]]></content>
  </entry>
  
</feed>
